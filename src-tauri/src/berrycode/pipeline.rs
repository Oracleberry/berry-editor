//! BerryFlow - n8n-style Agent Pipeline Engine
//!
//! ãƒãƒ¼ãƒ‰ã‚’ã¤ãªã’ã¦ã€çµæœã‚’æ¬¡ã®å·¥ç¨‹ã«æ¸¡ã—ã€æ¡ä»¶åˆ†å²ã§ãƒ«ãƒ¼ãƒ—ã•ã›ã‚‹ä»•çµ„ã¿

use anyhow::{anyhow, Result};
use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::sync::Mutex;
use tracing::{info, warn};

use crate::berrycode::llm::{LLMClient, Message};
use crate::berrycode::conversation_engine::{ConversationEngine, ToolCallback};
use crate::berrycode::models::Model;
use crate::berrycode::berryflow_config::BerryFlowConfig;
use crate::berrycode::notifications::Notifier;

/// ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€²æ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowProgressMessage {
    pub node_id: String,
    pub node_name: String,
    pub status: String, // "running", "success", "failure"
    pub message: String,
    pub loop_count: usize,
}

/// é€²æ—é€ä¿¡ç”¨ã®ãƒãƒ£ãƒãƒ«
pub type ProgressSender = tokio::sync::mpsc::UnboundedSender<WorkflowProgressMessage>;

/// ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
pub type SnapshotSaver = Arc<
    dyn Fn(String, String, String, String, String) -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<()>> + Send>>
        + Send
        + Sync,
>;

/// ä¸€æ™‚åœæ­¢ãƒ•ãƒ©ã‚°ãƒãƒƒãƒ—
pub type PauseFlags = Arc<Mutex<std::collections::HashMap<String, bool>>>;

/// å†é–‹ã‚·ã‚°ãƒŠãƒ«ãƒãƒƒãƒ—
pub type ResumeSignals = Arc<Mutex<std::collections::HashMap<String, tokio::sync::mpsc::UnboundedSender<()>>>>;

/// ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ãƒãƒƒãƒ—
pub type CancelFlags = Arc<Mutex<std::collections::HashMap<String, bool>>>;

/// ãƒãƒ¼ãƒ‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç¨®åˆ¥
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum NodeAction {
    /// è¨­è¨ˆãƒ•ã‚§ãƒ¼ã‚º
    Design,
    /// å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º
    Implement,
    /// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    Test,
    /// ã‚¨ãƒ©ãƒ¼ä¿®æ­£
    Fix,
    /// ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
    Refactor,
    /// ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œ
    Custom { prompt: String },
    /// HTTP APIã‚³ãƒ¼ãƒ«
    HttpRequest {
        url: String,
        method: String,
        headers: Option<std::collections::HashMap<String, String>>,
        body: Option<String>,
    },
    /// ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆJavaScriptå¼ã‚’ä½¿ç”¨ï¼‰
    DataTransform {
        script: String,
    },
    /// ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œï¼ˆèª­ã¿è¾¼ã¿/æ›¸ãè¾¼ã¿ï¼‰
    FileOperation {
        operation: String, // "read" or "write"
        file_path: String,
        content: Option<String>,
    },
    /// ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œï¼ˆä»»æ„ã®ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ï¼‰
    ScriptExecution {
        language: String, // "bash", "python", "node", etc.
        script: String,
    },
}

/// æ¡ä»¶ãƒã‚§ãƒƒã‚¯ç¨®åˆ¥
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum ConditionCheck {
    /// ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹
    CoverageLessThan { threshold: f64 },
    /// ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒé–¾å€¤ä»¥ä¸Š
    CoverageGreaterOrEqual { threshold: f64 },
    /// å®Ÿè¡Œæ™‚é–“ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹
    ExecutionTimeGreaterThan { threshold_ms: u64 },
    /// ãƒ†ã‚¹ãƒˆå¤±æ•—æ•°ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹
    FailedTestsGreaterThan { threshold: usize },
    /// ã‚«ã‚¹ã‚¿ãƒ æ¡ä»¶ï¼ˆã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã®çµ‚äº†ã‚³ãƒ¼ãƒ‰ã§åˆ¤å®šï¼‰
    CustomCommand { command: String, expect_success: bool },
    /// è¤‡æ•°æ¡ä»¶ã®ANDçµåˆï¼ˆã™ã¹ã¦çœŸã®å ´åˆã«çœŸï¼‰
    And { conditions: Vec<ConditionCheck> },
    /// è¤‡æ•°æ¡ä»¶ã®ORçµåˆï¼ˆã„ãšã‚Œã‹çœŸã®å ´åˆã«çœŸï¼‰
    Or { conditions: Vec<ConditionCheck> },
    /// æ¡ä»¶ã®å¦å®š
    Not { condition: Box<ConditionCheck> },
}

/// æ¡ä»¶ä»˜ãé·ç§»
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConditionalTransition {
    /// æ¡ä»¶
    pub condition: ConditionCheck,
    /// æ¡ä»¶ã‚’æº€ãŸã—ãŸå ´åˆã®æ¬¡ã®ãƒãƒ¼ãƒ‰ID
    pub next_node_id: String,
}

/// ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®1ã¤ã®ãƒãƒ¼ãƒ‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FlowNode {
    /// ãƒãƒ¼ãƒ‰ID
    pub id: String,
    /// ãƒãƒ¼ãƒ‰åï¼ˆè¡¨ç¤ºç”¨ï¼‰
    pub name: String,
    /// å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    pub action: NodeAction,
    /// æˆåŠŸæ™‚ã®æ¬¡ã®ãƒãƒ¼ãƒ‰ID
    pub next_on_success: Option<String>,
    /// å¤±æ•—æ™‚ã®æ¬¡ã®ãƒãƒ¼ãƒ‰IDï¼ˆã“ã‚ŒãŒãƒ«ãƒ¼ãƒ—ã‚’ä½œã‚‹ï¼‰
    pub next_on_failure: Option<String>,
    /// æ¡ä»¶ä»˜ãé·ç§»ï¼ˆæˆåŠŸæ™‚ã«è¿½åŠ ã§ãƒã‚§ãƒƒã‚¯ï¼‰
    pub conditional_transitions: Option<Vec<ConditionalTransition>>,
    /// ä¸¦åˆ—å®Ÿè¡Œã™ã‚‹ãƒãƒ¼ãƒ‰IDãƒªã‚¹ãƒˆï¼ˆã“ã®ãƒãƒ¼ãƒ‰ã¨ä¸¦è¡Œã—ã¦å®Ÿè¡Œï¼‰
    pub parallel_nodes: Option<Vec<String>>,
}

/// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®šç¾©
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Pipeline {
    /// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ID
    pub id: String,
    /// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å
    pub name: String,
    /// ãƒãƒ¼ãƒ‰ä¸€è¦§ï¼ˆID -> Nodeï¼‰
    pub nodes: HashMap<String, FlowNode>,
    /// é–‹å§‹ãƒãƒ¼ãƒ‰ID
    pub start_node_id: String,
    /// æœ€å¤§ãƒ«ãƒ¼ãƒ—å›æ•°ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰
    pub max_loops: usize,
    /// ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰None = ç„¡åˆ¶é™
    #[serde(default)]
    pub timeout_seconds: Option<u64>,
}

/// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ‹¡å¼µ
pub struct PipelineExecutor {
    pub llm_client: Option<LLMClient>,
    pub model: Option<Model>,
}

/// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum PipelineState {
    Running,
    Paused { at_node: String },
    Completed,
    Failed { error: String },
}

/// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
#[derive(Debug, Clone)]
pub struct PipelineContext {
    /// ç¾åœ¨ã®ãƒãƒ¼ãƒ‰ID
    pub current_node_id: String,
    /// å‰ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰ã®å‡ºåŠ›ï¼ˆè¨­è¨ˆæ›¸ã€ã‚³ãƒ¼ãƒ‰ã€ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãªã©ï¼‰
    pub context_data: String,
    /// ãƒ«ãƒ¼ãƒ—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    pub loop_count: usize,
    /// å®Ÿè¡Œå±¥æ­´
    pub execution_history: Vec<ExecutionRecord>,
    /// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹
    pub state: PipelineState,
}

/// å®Ÿè¡Œå±¥æ­´ã®1ãƒ¬ã‚³ãƒ¼ãƒ‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionRecord {
    pub node_id: String,
    pub node_name: String,
    pub action: NodeAction,
    pub success: bool,
    pub output: String,
    pub timestamp: String,
    /// ãƒãƒ¼ãƒ‰å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
    pub duration_ms: u64,
    /// å®Ÿè¡Œæ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    #[serde(skip_serializing_if = "Option::is_none")]
    pub metrics: Option<ExecutionMetrics>,
}

/// å®Ÿè¡Œãƒ¡ãƒˆãƒªã‚¯ã‚¹
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct ExecutionMetrics {
    /// ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆ0.0 - 100.0ï¼‰
    pub coverage: Option<f64>,
    /// å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
    pub execution_time_ms: Option<u64>,
    /// å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆæ•°
    pub failed_tests: Option<usize>,
    /// åˆè¨ˆãƒ†ã‚¹ãƒˆæ•°
    pub total_tests: Option<usize>,
}

/// ãƒãƒ¼ãƒ‰å®Ÿè¡Œçµæœ
#[derive(Debug)]
pub enum NodeResult {
    Success(String, ExecutionMetrics),
    Failure(String),
}

/// ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileSnapshot {
    pub file_path: String,
    pub content: String,
    pub timestamp: String,
}

/// ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkflowSnapshot {
    pub snapshot_id: String,
    pub execution_id: String,
    pub node_id: String,
    pub node_name: String,
    pub files: Vec<FileSnapshot>,
    pub timestamp: String,
}

impl Pipeline {
    /// æ–°ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ
    pub fn new(id: String, name: String, start_node_id: String) -> Self {
        Self {
            id,
            name,
            nodes: HashMap::new(),
            start_node_id,
            max_loops: 5,
            timeout_seconds: None,
        }
    }

    /// ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
    pub fn add_node(&mut self, node: FlowNode) {
        self.nodes.insert(node.id.clone(), node);
    }

    /// æ¡ä»¶ã‚’è©•ä¾¡
    fn evaluate_condition<'a>(
        &'a self,
        condition: &'a ConditionCheck,
        metrics: &'a ExecutionMetrics,
        project_root: &'a PathBuf,
    ) -> std::pin::Pin<Box<dyn std::future::Future<Output = Result<bool>> + Send + 'a>> {
        Box::pin(async move {
        match condition {
            ConditionCheck::CoverageLessThan { threshold } => {
                if let Some(coverage) = metrics.coverage {
                    Ok(coverage < *threshold)
                } else {
                    Ok(false) // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒãªã„å ´åˆã¯æ¡ä»¶ã‚’æº€ãŸã•ãªã„
                }
            }
            ConditionCheck::CoverageGreaterOrEqual { threshold } => {
                if let Some(coverage) = metrics.coverage {
                    Ok(coverage >= *threshold)
                } else {
                    Ok(false)
                }
            }
            ConditionCheck::ExecutionTimeGreaterThan { threshold_ms } => {
                if let Some(exec_time) = metrics.execution_time_ms {
                    Ok(exec_time > *threshold_ms)
                } else {
                    Ok(false)
                }
            }
            ConditionCheck::FailedTestsGreaterThan { threshold } => {
                if let Some(failed) = metrics.failed_tests {
                    Ok(failed > *threshold)
                } else {
                    Ok(false)
                }
            }
            ConditionCheck::CustomCommand { command, expect_success } => {
                // ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
                let output = tokio::process::Command::new("sh")
                    .arg("-c")
                    .arg(command)
                    .current_dir(project_root)
                    .output()
                    .await?;

                Ok(output.status.success() == *expect_success)
            }
            ConditionCheck::And { conditions } => {
                // ã™ã¹ã¦ã®æ¡ä»¶ãŒçœŸã®å ´åˆã®ã¿çœŸ
                for condition in conditions {
                    if !self.evaluate_condition(condition, metrics, project_root).await? {
                        return Ok(false);
                    }
                }
                Ok(true)
            }
            ConditionCheck::Or { conditions } => {
                // ã„ãšã‚Œã‹ã®æ¡ä»¶ãŒçœŸã®å ´åˆã«çœŸ
                for condition in conditions {
                    if self.evaluate_condition(condition, metrics, project_root).await? {
                        return Ok(true);
                    }
                }
                Ok(false)
            }
            ConditionCheck::Not { condition } => {
                // æ¡ä»¶ã®å¦å®š
                let result = self.evaluate_condition(condition, metrics, project_root).await?;
                Ok(!result)
            }
        }
        })
    }

    /// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
    pub async fn run(
        &self,
        project_root: &PathBuf,
        initial_prompt: String,
        progress_tx: Option<ProgressSender>,
        execution_id: Option<String>,
        snapshot_saver: Option<SnapshotSaver>,
        pause_flags: Option<PauseFlags>,
        resume_signals: Option<ResumeSignals>,
        cancel_flags: Option<CancelFlags>,
    ) -> Result<PipelineContext> {
        info!("Starting pipeline execution: {}", self.name);

        // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§å®Ÿè¡Œ
        if let Some(timeout_secs) = self.timeout_seconds {
            let timeout_duration = std::time::Duration::from_secs(timeout_secs);
            match tokio::time::timeout(
                timeout_duration,
                self.run_internal(
                    project_root,
                    initial_prompt,
                    progress_tx,
                    execution_id,
                    snapshot_saver,
                    pause_flags,
                    resume_signals,
                    cancel_flags,
                ),
            )
            .await
            {
                Ok(result) => result,
                Err(_) => Err(anyhow!(
                    "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ{}ç§’ï¼‰",
                    timeout_secs
                )),
            }
        } else {
            // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ã§å®Ÿè¡Œ
            self.run_internal(
                project_root,
                initial_prompt,
                progress_tx,
                execution_id,
                snapshot_saver,
                pause_flags,
                resume_signals,
                cancel_flags,
            )
            .await
        }
    }

    /// ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å†…éƒ¨å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯
    async fn run_internal(
        &self,
        project_root: &PathBuf,
        initial_prompt: String,
        progress_tx: Option<ProgressSender>,
        execution_id: Option<String>,
        snapshot_saver: Option<SnapshotSaver>,
        pause_flags: Option<PauseFlags>,
        resume_signals: Option<ResumeSignals>,
        cancel_flags: Option<CancelFlags>,
    ) -> Result<PipelineContext> {
        let mut context = PipelineContext {
            current_node_id: self.start_node_id.clone(),
            context_data: initial_prompt,
            loop_count: 0,
            execution_history: Vec::new(),
            state: PipelineState::Running,
        };

        while let Some(node) = self.nodes.get(&context.current_node_id) {
            info!("Executing node: {} ({})", node.name, node.id);

            // ä¸€æ™‚åœæ­¢ãƒã‚§ãƒƒã‚¯ï¼ˆexecution_idãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if let (Some(ref exec_id), Some(ref flags)) = (&execution_id, &pause_flags) {
                let mut paused_message_sent = false;

                loop {
                    let is_paused = {
                        let pause_map = flags.lock().await;
                        pause_map.get(exec_id).copied().unwrap_or(false)
                    };

                    if is_paused {
                        if !paused_message_sent {
                            info!("Pipeline {} is paused, waiting for resume...", exec_id);

                            // é€²æ—é€ä¿¡: ä¸€æ™‚åœæ­¢ä¸­
                            if let Some(ref tx) = progress_tx {
                                let _ = tx.send(WorkflowProgressMessage {
                                    node_id: node.id.clone(),
                                    node_name: node.name.clone(),
                                    status: "paused".to_string(),
                                    message: format!("{}ã§ä¸€æ™‚åœæ­¢ä¸­...", node.name),
                                    loop_count: context.loop_count,
                                });
                            }

                            paused_message_sent = true;
                        }

                        // 1ç§’å¾…ã£ã¦ã‹ã‚‰å†ãƒã‚§ãƒƒã‚¯
                        tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
                    } else {
                        if paused_message_sent {
                            info!("Pipeline {} resumed", exec_id);
                        }
                        break;
                    }
                }
            }

            // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒã‚§ãƒƒã‚¯ï¼ˆexecution_idãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if let (Some(ref exec_id), Some(ref flags)) = (&execution_id, &cancel_flags) {
                let is_cancelled = {
                    let cancel_map = flags.lock().await;
                    cancel_map.get(exec_id).copied().unwrap_or(false)
                };

                if is_cancelled {
                    warn!("Pipeline {} was cancelled", exec_id);

                    // é€²æ—é€ä¿¡: ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                    if let Some(ref tx) = progress_tx {
                        let _ = tx.send(WorkflowProgressMessage {
                            node_id: node.id.clone(),
                            node_name: node.name.clone(),
                            status: "cancelled".to_string(),
                            message: format!("{}ã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ", node.name),
                            loop_count: context.loop_count,
                        });
                    }

                    return Err(anyhow!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ"));
                }
            }

            // é€²æ—é€ä¿¡: ãƒãƒ¼ãƒ‰é–‹å§‹
            if let Some(ref tx) = progress_tx {
                let _ = tx.send(WorkflowProgressMessage {
                    node_id: node.id.clone(),
                    node_name: node.name.clone(),
                    status: "running".to_string(),
                    message: format!("{}ã‚’å®Ÿè¡Œä¸­...", node.name),
                    loop_count: context.loop_count,
                });
            }

            // ãƒ«ãƒ¼ãƒ—å›æ•°ãƒã‚§ãƒƒã‚¯
            if context.loop_count >= self.max_loops {
                warn!("Max loop limit reached: {}", self.max_loops);

                // é€²æ—é€ä¿¡: å¤±æ•—
                if let Some(ref tx) = progress_tx {
                    let _ = tx.send(WorkflowProgressMessage {
                        node_id: node.id.clone(),
                        node_name: node.name.clone(),
                        status: "failure".to_string(),
                        message: format!("æœ€å¤§ãƒ«ãƒ¼ãƒ—å›æ•°({})ã«é”ã—ã¾ã—ãŸ", self.max_loops),
                        loop_count: context.loop_count,
                    });
                }

                return Err(anyhow!("æœ€å¤§ãƒ«ãƒ¼ãƒ—å›æ•°ã«é”ã—ã¾ã—ãŸ: {} å›", self.max_loops));
            }

            // ãƒãƒ¼ãƒ‰ã‚’å®Ÿè¡Œï¼ˆæ™‚é–“è¨ˆæ¸¬ï¼‰
            let node_start = std::time::Instant::now();
            let result = self.execute_node(node, &context.context_data, project_root).await?;
            let node_duration_ms = node_start.elapsed().as_millis() as u64;

            // ä¸¦åˆ—ãƒãƒ¼ãƒ‰ãŒã‚ã‚Œã°å®Ÿè¡Œ
            let mut parallel_results = Vec::new();
            if let Some(ref parallel_node_ids) = node.parallel_nodes {
                info!("Executing {} parallel nodes", parallel_node_ids.len());

                let mut parallel_tasks = Vec::new();

                for parallel_node_id in parallel_node_ids {
                    if let Some(parallel_node) = self.nodes.get(parallel_node_id) {
                        // é€²æ—é€ä¿¡: ä¸¦åˆ—ãƒãƒ¼ãƒ‰é–‹å§‹
                        if let Some(ref tx) = progress_tx {
                            let _ = tx.send(WorkflowProgressMessage {
                                node_id: parallel_node.id.clone(),
                                node_name: parallel_node.name.clone(),
                                status: "running".to_string(),
                                message: format!("{}ã‚’ä¸¦åˆ—å®Ÿè¡Œä¸­...", parallel_node.name),
                                loop_count: context.loop_count,
                            });
                        }

                        let parallel_node_clone = parallel_node.clone();
                        let context_data = context.context_data.clone();
                        let project_root_clone = project_root.clone();

                        // ä¸¦åˆ—ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆ
                        let task = tokio::spawn(async move {
                            let start = std::time::Instant::now();
                            let result = Self::execute_node_static(&parallel_node_clone, &context_data, &project_root_clone).await;
                            let duration_ms = start.elapsed().as_millis() as u64;
                            (parallel_node_clone.id.clone(),
                             parallel_node_clone.name.clone(),
                             result,
                             duration_ms)
                        });

                        parallel_tasks.push(task);
                    } else {
                        warn!("Parallel node not found: {}", parallel_node_id);
                    }
                }

                // ã™ã¹ã¦ã®ä¸¦åˆ—ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…ã¤
                for task in parallel_tasks {
                    match task.await {
                        Ok((node_id, node_name, task_result, duration_ms)) => {
                            match task_result {
                                Ok(NodeResult::Success(output, metrics)) => {
                                    info!("Parallel node {} completed successfully", node_id);

                                    // é€²æ—é€ä¿¡: ä¸¦åˆ—ãƒãƒ¼ãƒ‰æˆåŠŸ
                                    if let Some(ref tx) = progress_tx {
                                        let _ = tx.send(WorkflowProgressMessage {
                                            node_id: node_id.clone(),
                                            node_name: node_name.clone(),
                                            status: "success".to_string(),
                                            message: format!("{}ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼ˆä¸¦åˆ—ï¼‰", node_name),
                                            loop_count: context.loop_count,
                                        });
                                    }

                                    // ä¸¦åˆ—ãƒãƒ¼ãƒ‰ã®çµæœã‚’åé›†
                                    parallel_results.push(format!("ã€{}ã€‘\n{}", node_name, output));

                                    // ä¸¦åˆ—ãƒãƒ¼ãƒ‰ã®çµæœã‚’å±¥æ­´ã«è¨˜éŒ²
                                    context.execution_history.push(ExecutionRecord {
                                        node_id: node_id.clone(),
                                        node_name: node_name.clone(),
                                        action: NodeAction::Custom { prompt: "Parallel execution".to_string() },
                                        success: true,
                                        output,
                                        timestamp: chrono::Utc::now().to_rfc3339(),
                                        duration_ms,
                                        metrics: Some(metrics),
                                    });
                                }
                                Ok(NodeResult::Failure(error_log)) => {
                                    warn!("Parallel node {} failed: {}", node_id, error_log);

                                    // é€²æ—é€ä¿¡: ä¸¦åˆ—ãƒãƒ¼ãƒ‰å¤±æ•—
                                    if let Some(ref tx) = progress_tx {
                                        let _ = tx.send(WorkflowProgressMessage {
                                            node_id: node_id.clone(),
                                            node_name: node_name.clone(),
                                            status: "failure".to_string(),
                                            message: format!("{}ãŒå¤±æ•—ã—ã¾ã—ãŸï¼ˆä¸¦åˆ—ï¼‰", node_name),
                                            loop_count: context.loop_count,
                                        });
                                    }

                                    // ä¸¦åˆ—ãƒãƒ¼ãƒ‰ã®å¤±æ•—çµæœã‚‚åé›†
                                    parallel_results.push(format!("ã€{}ï¼ˆå¤±æ•—ï¼‰ã€‘\n{}", node_name, error_log));

                                    // ä¸¦åˆ—ãƒãƒ¼ãƒ‰ã®å¤±æ•—ã‚’å±¥æ­´ã«è¨˜éŒ²
                                    context.execution_history.push(ExecutionRecord {
                                        node_id: node_id.clone(),
                                        node_name: node_name.clone(),
                                        action: NodeAction::Custom { prompt: "Parallel execution".to_string() },
                                        success: false,
                                        output: error_log,
                                        timestamp: chrono::Utc::now().to_rfc3339(),
                                        duration_ms,
                                        metrics: None,
                                    });
                                }
                                Err(e) => {
                                    warn!("Parallel node {} execution error: {}", node_id, e);
                                    parallel_results.push(format!("ã€{}ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰ã€‘\n{}", node_name, e));
                                }
                            }
                        }
                        Err(e) => {
                            warn!("Parallel task join error: {}", e);
                        }
                    }
                }
            }

            // å®Ÿè¡Œå±¥æ­´ã«è¨˜éŒ²
            let record = ExecutionRecord {
                node_id: node.id.clone(),
                node_name: node.name.clone(),
                action: node.action.clone(),
                success: matches!(result, NodeResult::Success(_, _)),
                output: match &result {
                    NodeResult::Success(s, _) => s.clone(),
                    NodeResult::Failure(s) => s.clone(),
                },
                timestamp: chrono::Utc::now().to_rfc3339(),
                duration_ms: node_duration_ms,
                metrics: match &result {
                    NodeResult::Success(_, m) => Some(m.clone()),
                    NodeResult::Failure(_) => None,
                },
            };
            context.execution_history.push(record);

            // çµæœã«å¿œã˜ã¦æ¬¡ã®ãƒãƒ¼ãƒ‰ã¸é·ç§»
            match result {
                NodeResult::Success(output, metrics) => {
                    // é€²æ—é€ä¿¡: æˆåŠŸ
                    if let Some(ref tx) = progress_tx {
                        let _ = tx.send(WorkflowProgressMessage {
                            node_id: node.id.clone(),
                            node_name: node.name.clone(),
                            status: "success".to_string(),
                            message: format!("{}ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ", node.name),
                            loop_count: context.loop_count,
                        });
                    }

                    context.context_data = output;

                    // ä¸¦åˆ—ãƒãƒ¼ãƒ‰ã®çµæœã‚’çµ±åˆ
                    if !parallel_results.is_empty() {
                        context.context_data.push_str("\n\n--- ä¸¦åˆ—å®Ÿè¡Œçµæœ ---\n");
                        context.context_data.push_str(&parallel_results.join("\n\n"));
                    }

                    // ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è‡ªå‹•ä½œæˆï¼ˆexecution_idã¨snapshot_saverãŒä¸¡æ–¹ã‚ã‚‹å ´åˆã®ã¿ï¼‰
                    if let (Some(ref exec_id), Some(ref saver)) = (&execution_id, &snapshot_saver) {
                        info!("Creating snapshot for node {} in execution {}", node.id, exec_id);

                        // è¿½è·¡å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                        match Self::get_tracked_files(project_root).await {
                            Ok(tracked_files) => {
                                // ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä½œæˆ
                                match Self::create_snapshot(
                                    exec_id,
                                    &node.id,
                                    &node.name,
                                    project_root,
                                    &tracked_files,
                                ).await {
                                    Ok(snapshot) => {
                                        // ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’DBã«ä¿å­˜
                                        let snapshot_data = serde_json::to_string(&snapshot).unwrap_or_default();
                                        let snapshot_id = snapshot.snapshot_id.clone();
                                        let node_id = node.id.clone();
                                        let node_name = node.name.clone();
                                        let exec_id_clone = exec_id.clone();

                                        match saver(
                                            snapshot_id.clone(),
                                            exec_id_clone,
                                            node_id,
                                            node_name,
                                            snapshot_data,
                                        ).await {
                                            Ok(_) => {
                                                info!("Snapshot {} saved successfully with {} files",
                                                      snapshot_id, snapshot.files.len());
                                            }
                                            Err(e) => {
                                                warn!("Failed to save snapshot to database: {}", e);
                                            }
                                        }
                                    }
                                    Err(e) => {
                                        warn!("Failed to create snapshot: {}", e);
                                    }
                                }
                            }
                            Err(e) => {
                                warn!("Failed to get tracked files for snapshot: {}", e);
                            }
                        }
                    }

                    // æ¡ä»¶ä»˜ãé·ç§»ã‚’ãƒã‚§ãƒƒã‚¯
                    let mut next_node_determined = false;
                    if let Some(ref transitions) = node.conditional_transitions {
                        for transition in transitions {
                            if self.evaluate_condition(&transition.condition, &metrics, project_root).await? {
                                info!(
                                    "Conditional transition triggered: {:?} -> {}",
                                    transition.condition, transition.next_node_id
                                );
                                context.current_node_id = transition.next_node_id.clone();
                                next_node_determined = true;
                                break;
                            }
                        }
                    }

                    // æ¡ä»¶ä»˜ãé·ç§»ãŒãªã‘ã‚Œã°é€šå¸¸ã®æˆåŠŸæ™‚é·ç§»
                    if !next_node_determined {
                        if let Some(next_id) = &node.next_on_success {
                            context.current_node_id = next_id.clone();
                        } else {
                            info!("Pipeline completed successfully");
                            break;
                        }
                    }
                }
                NodeResult::Failure(error_log) => {
                    // é€²æ—é€ä¿¡: å¤±æ•—
                    if let Some(ref tx) = progress_tx {
                        let _ = tx.send(WorkflowProgressMessage {
                            node_id: node.id.clone(),
                            node_name: node.name.clone(),
                            status: "failure".to_string(),
                            message: format!("{}ãŒå¤±æ•—ã—ã¾ã—ãŸ", node.name),
                            loop_count: context.loop_count,
                        });
                    }

                    context.context_data = error_log.clone();
                    if let Some(fix_node_id) = &node.next_on_failure {
                        warn!("Node failed, moving to fix node: {}", fix_node_id);
                        context.current_node_id = fix_node_id.clone();
                        context.loop_count += 1;
                    } else {
                        return Err(anyhow!("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå¤±æ•—ã—ã¾ã—ãŸ"));
                    }
                }
            }
        }

        Ok(context)
    }

    /// å€‹åˆ¥ã®ãƒãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
    async fn execute_node(
        &self,
        node: &FlowNode,
        input_context: &str,
        project_root: &PathBuf,
    ) -> Result<NodeResult> {
        Self::execute_node_static(node, input_context, project_root).await
    }

    /// å€‹åˆ¥ã®ãƒãƒ¼ãƒ‰ã‚’å®Ÿè¡Œï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ - ä¸¦åˆ—å®Ÿè¡Œç”¨ï¼‰
    async fn execute_node_static(
        node: &FlowNode,
        input_context: &str,
        project_root: &PathBuf,
    ) -> Result<NodeResult> {
        match &node.action {
            NodeAction::Test => {
                // ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                Self::execute_test_static(project_root, input_context).await
            }
            NodeAction::Fix => {
                // ã‚¨ãƒ©ãƒ¼ä¿®æ­£ï¼ˆAIã«ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’æ¸¡ã—ã¦ä¿®æ­£ã•ã›ã‚‹ï¼‰
                Self::execute_fix_static(project_root, input_context).await
            }
            NodeAction::Design => {
                Self::execute_design_static(project_root, input_context).await
            }
            NodeAction::Implement => {
                Self::execute_implement_static(project_root, input_context).await
            }
            NodeAction::Refactor => {
                Self::execute_refactor_static(project_root, input_context).await
            }
            NodeAction::Custom { prompt } => {
                Self::execute_custom_static(project_root, input_context, prompt).await
            }
            NodeAction::HttpRequest { url, method, headers, body } => {
                Self::execute_http_request_static(url, method, headers.as_ref(), body.as_ref()).await
            }
            NodeAction::DataTransform { script } => {
                Self::execute_data_transform_static(input_context, script).await
            }
            NodeAction::FileOperation { operation, file_path, content } => {
                Self::execute_file_operation_static(project_root, operation, file_path, content.as_ref()).await
            }
            NodeAction::ScriptExecution { language, script } => {
                Self::execute_script_static(project_root, language, script).await
            }
        }
    }

    /// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒãƒ¼ãƒ‰
    async fn execute_test(&self, project_root: &PathBuf, context: &str) -> Result<NodeResult> {
        Self::execute_test_static(project_root, context).await
    }

    /// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒãƒ¼ãƒ‰ï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    async fn execute_test_static(project_root: &PathBuf, _context: &str) -> Result<NodeResult> {
        info!("Running tests in {:?}", project_root);

        // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç¨®é¡ã‚’åˆ¤å®šã—ã¦ã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ããƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
        let (test_command, project_type) = if project_root.join("Cargo.toml").exists() {
            // Rustãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: cargo-tarpaulinã‚’è©¦ã™ã€ãªã‘ã‚Œã°é€šå¸¸ã®ãƒ†ã‚¹ãƒˆ
            let has_tarpaulin = tokio::process::Command::new("cargo")
                .arg("tarpaulin")
                .arg("--version")
                .output()
                .await
                .map(|o| o.status.success())
                .unwrap_or(false);

            if has_tarpaulin {
                ("cargo tarpaulin --out Stdout --output-dir target/coverage", "rust_coverage")
            } else {
                ("cargo test --no-fail-fast", "rust")
            }
        } else if project_root.join("package.json").exists() {
            // Node.jsãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: package.jsonã®test scriptã§ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç¢ºèª
            // npm test -- --coverage ã¾ãŸã¯ jest --coverage ã‚’è©¦ã™
            ("npm test -- --coverage 2>&1 || npm test", "node")
        } else if project_root.join("pytest.ini").exists() || project_root.join("setup.py").exists() {
            // Pythonãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: pytest-covã‚’è©¦ã™
            ("pytest --cov --cov-report=term 2>&1 || pytest", "python")
        } else {
            return Ok(NodeResult::Failure("ãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“".to_string()));
        };

        // å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆæ¸¬
        let start = std::time::Instant::now();

        // ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        let output = tokio::process::Command::new("sh")
            .arg("-c")
            .arg(test_command)
            .current_dir(project_root)
            .output()
            .await?;

        let execution_time_ms = start.elapsed().as_millis() as u64;

        let stdout = String::from_utf8_lossy(&output.stdout);
        let stderr = String::from_utf8_lossy(&output.stderr);
        let combined = format!("{}\n{}", stdout, stderr);

        // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡º
        let mut metrics = ExecutionMetrics {
            execution_time_ms: Some(execution_time_ms),
            ..Default::default()
        };

        // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡º
        match project_type {
            "rust_coverage" => {
                // cargo-tarpaulinã®å‡ºåŠ›ã‹ã‚‰ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æŠ½å‡º
                // ä¾‹: "47.37% coverage, 18/38 lines covered"
                if let Some(captures) = regex::Regex::new(r"(\d+\.\d+)% coverage")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    if let Some(cov) = captures.get(1).and_then(|m| m.as_str().parse::<f64>().ok()) {
                        metrics.coverage = Some(cov);
                    }
                }

                // ãƒ†ã‚¹ãƒˆæ•°ã‚’æŠ½å‡º
                if let Some(captures) = regex::Regex::new(r"test result: \w+\. (\d+) passed; (\d+) failed")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    let passed: usize = captures.get(1).and_then(|m| m.as_str().parse().ok()).unwrap_or(0);
                    let failed: usize = captures.get(2).and_then(|m| m.as_str().parse().ok()).unwrap_or(0);
                    metrics.total_tests = Some(passed + failed);
                    metrics.failed_tests = Some(failed);
                }
            }
            "rust" => {
                // é€šå¸¸ã®cargo testã®å‡ºåŠ›ã‹ã‚‰ãƒ†ã‚¹ãƒˆæ•°ã®ã¿æŠ½å‡º
                if let Some(captures) = regex::Regex::new(r"test result: \w+\. (\d+) passed; (\d+) failed")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    let passed: usize = captures.get(1).and_then(|m| m.as_str().parse().ok()).unwrap_or(0);
                    let failed: usize = captures.get(2).and_then(|m| m.as_str().parse().ok()).unwrap_or(0);
                    metrics.total_tests = Some(passed + failed);
                    metrics.failed_tests = Some(failed);
                }
            }
            "node" => {
                // Jestã®ã‚«ãƒãƒ¬ãƒƒã‚¸å‡ºåŠ›ã‚’æŠ½å‡º
                // ä¾‹: "All files | 85.71 | 66.67 | 100 | 85.71"
                if let Some(captures) = regex::Regex::new(r"All files\s+\|\s+(\d+\.?\d*)")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    if let Some(cov) = captures.get(1).and_then(|m| m.as_str().parse::<f64>().ok()) {
                        metrics.coverage = Some(cov);
                    }
                }

                // ãƒ†ã‚¹ãƒˆæ•°ã‚’æŠ½å‡º
                // ä¾‹: "Tests: 5 passed, 5 total"
                if let Some(captures) = regex::Regex::new(r"Tests:\s+(\d+)\s+passed.*?(\d+)\s+total")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    let total: usize = captures.get(2).and_then(|m| m.as_str().parse().ok()).unwrap_or(0);
                    let passed: usize = captures.get(1).and_then(|m| m.as_str().parse().ok()).unwrap_or(0);
                    metrics.total_tests = Some(total);
                    metrics.failed_tests = Some(total - passed);
                }
            }
            "python" => {
                // pytest-covã®ã‚«ãƒãƒ¬ãƒƒã‚¸å‡ºåŠ›ã‚’æŠ½å‡º
                // ä¾‹: "TOTAL 156 39 75%"
                if let Some(captures) = regex::Regex::new(r"TOTAL\s+\d+\s+\d+\s+(\d+)%")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    if let Some(cov) = captures.get(1).and_then(|m| m.as_str().parse::<f64>().ok()) {
                        metrics.coverage = Some(cov);
                    }
                }

                // ãƒ†ã‚¹ãƒˆæ•°ã‚’æŠ½å‡º
                // ä¾‹: "5 passed in 0.12s"
                if let Some(captures) = regex::Regex::new(r"(\d+)\s+passed")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    if let Some(passed) = captures.get(1).and_then(|m| m.as_str().parse::<usize>().ok()) {
                        metrics.total_tests = Some(passed);
                        metrics.failed_tests = Some(0);
                    }
                }

                // å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã‚‚æŠ½å‡º
                if let Some(captures) = regex::Regex::new(r"(\d+)\s+failed")
                    .ok()
                    .and_then(|re| re.captures(&combined))
                {
                    if let Some(failed) = captures.get(1).and_then(|m| m.as_str().parse::<usize>().ok()) {
                        metrics.failed_tests = Some(failed);
                        if let Some(total) = metrics.total_tests {
                            metrics.total_tests = Some(total + failed);
                        }
                    }
                }
            }
            _ => {}
        }

        if output.status.success() {
            let summary = if let Some(cov) = metrics.coverage {
                format!("âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ (ã‚«ãƒãƒ¬ãƒƒã‚¸: {:.2}%)\n\n{}", cov, combined)
            } else {
                format!("âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ\n\n{}", combined)
            };

            Ok(NodeResult::Success(summary, metrics))
        } else {
            Ok(NodeResult::Failure(format!("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—\n\n{}", combined)))
        }
    }

    /// ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒãƒ¼ãƒ‰ï¼ˆAIã‚’å‘¼ã³å‡ºã™ï¼‰
    async fn execute_fix(&self, project_root: &PathBuf, error_log: &str) -> Result<NodeResult> {
        Self::execute_fix_static(project_root, error_log).await
    }

    /// ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒãƒ¼ãƒ‰ï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    async fn execute_fix_static(project_root: &PathBuf, error_log: &str) -> Result<NodeResult> {
        info!("Executing fix node with error log");

        // ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è§£æã—ã¦ã€å•é¡Œã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ç‰¹å®š
        let fix_prompt = Self::build_fix_prompt_static(error_log, project_root)?;

        // LLMã‚’ä½¿ã£ã¦å®Ÿéš›ã«ä¿®æ­£ã‚’å®Ÿè¡Œ
        match Self::execute_with_llm_static(project_root, &fix_prompt).await {
            Ok(result) => {
                info!("Fix node completed successfully");
                Ok(NodeResult::Success(
                    format!("ğŸ”§ ä¿®æ­£å®Œäº†\n\n{}", result),
                    ExecutionMetrics::default(),
                ))
            }
            Err(e) => {
                warn!("Fix node LLM execution failed: {}", e);
                // LLMçµ±åˆãŒå¤±æ•—ã—ãŸå ´åˆã§ã‚‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯è¿”ã™
                Ok(NodeResult::Success(
                    format!(
                        "ğŸ”§ ä¿®æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆLLMå®Ÿè¡Œå¤±æ•—: {}ï¼‰\n\n{}",
                        e, fix_prompt
                    ),
                    ExecutionMetrics::default(),
                ))
            }
        }
    }

    /// ä¿®æ­£ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    fn build_fix_prompt(&self, error_log: &str, project_root: &PathBuf) -> Result<String> {
        Self::build_fix_prompt_static(error_log, project_root)
    }

    /// ä¿®æ­£ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    fn build_fix_prompt_static(error_log: &str, project_root: &PathBuf) -> Result<String> {
        let prompt = format!(
            r#"ã‚ãªãŸã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {}

ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼:
```
{}
```

æŒ‡ç¤º:
1. ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’åˆ†æã—ã¦ã€å•é¡Œã®åŸå› ã‚’ç‰¹å®šã—ã¦ãã ã•ã„
2. è©²å½“ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã—ã¦ãã ã•ã„
3. write_file ã¾ãŸã¯ edit_file ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ä¿®æ­£ã‚’é©ç”¨ã—ã¦ãã ã•ã„
4. ä¿®æ­£å†…å®¹ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„

æ³¨æ„äº‹é …:
- ãƒ†ã‚¹ãƒˆãŒé€šã‚‹ã‚ˆã†ã«ç¢ºå®Ÿã«ä¿®æ­£ã—ã¦ãã ã•ã„
- ã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’ç¶­æŒã—ã¦ãã ã•ã„
- ä¸è¦ãªå¤‰æ›´ã¯é¿ã‘ã¦ãã ã•ã„
"#,
            project_root.display(),
            error_log
        );

        Ok(prompt)
    }

    /// è¨­è¨ˆãƒãƒ¼ãƒ‰
    async fn execute_design(&self, project_root: &PathBuf, requirement: &str) -> Result<NodeResult> {
        Self::execute_design_static(project_root, requirement).await
    }

    /// è¨­è¨ˆãƒãƒ¼ãƒ‰ï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    async fn execute_design_static(project_root: &PathBuf, requirement: &str) -> Result<NodeResult> {
        info!("Executing design node");

        let design_prompt = format!(
            r#"ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è¦ä»¶ã«ã¤ã„ã¦è©³ç´°ãªè¨­è¨ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {}

è¦ä»¶:
{}

æŒ‡ç¤º:
1. è¦ä»¶ã‚’åˆ†æã—ã¦ã€å®Ÿè£…ã™ã¹ãæ©Ÿèƒ½ã‚’æ˜ç¢ºåŒ–ã—ã¦ãã ã•ã„
2. å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆã‚’è¨­è¨ˆã—ã¦ãã ã•ã„
3. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å®šç¾©ã—ã¦ãã ã•ã„
4. å®Ÿè£…æ‰‹é †ã‚’æ®µéšçš„ã«ç¤ºã—ã¦ãã ã•ã„

è¨­è¨ˆã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„:
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦
- ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ
- ä¸»è¦ãªé–¢æ•°/ã‚¯ãƒ©ã‚¹ã®ã‚·ã‚°ãƒãƒãƒ£
- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼
"#,
            project_root.display(),
            requirement
        );

        // LLMã‚’ä½¿ã£ã¦è¨­è¨ˆã‚’å®Ÿè¡Œ
        match Self::execute_with_llm_static(project_root, &design_prompt).await {
            Ok(result) => {
                info!("Design node completed successfully");
                Ok(NodeResult::Success(
                    format!("ğŸ“ è¨­è¨ˆå®Œäº†\n\n{}", result),
                    ExecutionMetrics::default(),
                ))
            }
            Err(e) => {
                warn!("Design node LLM execution failed: {}", e);
                Ok(NodeResult::Success(
                    format!("ğŸ“ è¨­è¨ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆLLMå®Ÿè¡Œå¤±æ•—: {}ï¼‰\n\n{}", e, design_prompt),
                    ExecutionMetrics::default(),
                ))
            }
        }
    }

    /// å®Ÿè£…ãƒãƒ¼ãƒ‰
    async fn execute_implement(&self, project_root: &PathBuf, design: &str) -> Result<NodeResult> {
        Self::execute_implement_static(project_root, design).await
    }

    /// å®Ÿè£…ãƒãƒ¼ãƒ‰ï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    async fn execute_implement_static(project_root: &PathBuf, design: &str) -> Result<NodeResult> {
        info!("Executing implement node");

        let impl_prompt = format!(
            r#"ã‚ãªãŸã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆé–‹ç™ºè€…ã§ã™ã€‚ä»¥ä¸‹ã®è¨­è¨ˆã«åŸºã¥ã„ã¦å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {}

è¨­è¨ˆ:
{}

æŒ‡ç¤º:
1. è¨­è¨ˆã«å¾“ã£ã¦ã€å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„
2. write_file ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„
3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„
4. ã‚³ãƒ¼ãƒ‰ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦ã€å®Ÿè£…ã®æ„å›³ã‚’æ˜ç¢ºã«ã—ã¦ãã ã•ã„
"#,
            project_root.display(),
            design
        );

        // LLMã‚’ä½¿ã£ã¦å®Ÿè£…ã‚’å®Ÿè¡Œ
        match Self::execute_with_llm_static(project_root, &impl_prompt).await {
            Ok(result) => {
                info!("Implement node completed successfully");
                Ok(NodeResult::Success(
                    format!("ğŸ’» å®Ÿè£…å®Œäº†\n\n{}", result),
                    ExecutionMetrics::default(),
                ))
            }
            Err(e) => {
                warn!("Implement node LLM execution failed: {}", e);
                Ok(NodeResult::Success(
                    format!("ğŸ’» å®Ÿè£…ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆLLMå®Ÿè¡Œå¤±æ•—: {}ï¼‰\n\n{}", e, impl_prompt),
                    ExecutionMetrics::default(),
                ))
            }
        }
    }

    /// ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒãƒ¼ãƒ‰
    async fn execute_refactor(&self, project_root: &PathBuf, code: &str) -> Result<NodeResult> {
        Self::execute_refactor_static(project_root, code).await
    }

    /// ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒãƒ¼ãƒ‰ï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    async fn execute_refactor_static(project_root: &PathBuf, code: &str) -> Result<NodeResult> {
        info!("Executing refactor node");

        let refactor_prompt = format!(
            r#"ã‚ãªãŸã¯ã‚³ãƒ¼ãƒ‰å“è³ªã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {}

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{}

æŒ‡ç¤º:
1. ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§ã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„
2. é‡è¤‡ã‚’æ’é™¤ã—ã¦ãã ã•ã„
3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã§ãã‚‹ç®‡æ‰€ã‚’ç‰¹å®šã—ã¦ãã ã•ã„
4. edit_file ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦æ”¹å–„ã‚’é©ç”¨ã—ã¦ãã ã•ã„
"#,
            project_root.display(),
            code
        );

        // LLMã‚’ä½¿ã£ã¦ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
        match Self::execute_with_llm_static(project_root, &refactor_prompt).await {
            Ok(result) => {
                info!("Refactor node completed successfully");
                Ok(NodeResult::Success(
                    format!("ğŸ§¹ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†\n\n{}", result),
                    ExecutionMetrics::default(),
                ))
            }
            Err(e) => {
                warn!("Refactor node LLM execution failed: {}", e);
                Ok(NodeResult::Success(
                    format!("ğŸ§¹ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆLLMå®Ÿè¡Œå¤±æ•—: {}ï¼‰\n\n{}", e, refactor_prompt),
                    ExecutionMetrics::default(),
                ))
            }
        }
    }

    /// ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ãƒ‰
    async fn execute_custom(
        &self,
        project_root: &PathBuf,
        context: &str,
        prompt: &str,
    ) -> Result<NodeResult> {
        Self::execute_custom_static(project_root, context, prompt).await
    }

    /// ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ãƒ‰ï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    async fn execute_custom_static(
        project_root: &PathBuf,
        context: &str,
        prompt: &str,
    ) -> Result<NodeResult> {
        info!("Executing custom node");

        let full_prompt = format!(
            r#"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {}

ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¹ã‚¯:
{}

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{}

âš ï¸  å®Œå…¨ãªLLMçµ±åˆã¯é–‹ç™ºä¸­ã§ã™
"#,
            project_root.display(),
            prompt,
            context
        );

        Ok(NodeResult::Success(
            format!("ğŸ¯ ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ\n\n{}", full_prompt),
            ExecutionMetrics::default(),
        ))
    }

    /// LLMã‚’ä½¿ã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œ
    async fn execute_with_llm(&self, project_root: &PathBuf, prompt: &str) -> Result<String> {
        Self::execute_with_llm_static(project_root, prompt).await
    }

    /// LLMã‚’ä½¿ã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œï¼ˆé™çš„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    async fn execute_with_llm_static(project_root: &PathBuf, prompt: &str) -> Result<String> {
        info!("Executing with LLM");

        // ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
        let api_key = std::env::var("ANTHROPIC_API_KEY")
            .or_else(|_| std::env::var("OPENAI_API_KEY"))
            .map_err(|_| anyhow!("ANTHROPIC_API_KEY or OPENAI_API_KEY not set"))?;

        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«åã‚’æ±ºå®š
        let model_name = if std::env::var("ANTHROPIC_API_KEY").is_ok() {
            "claude-3-5-sonnet-20240620".to_string()
        } else {
            "gpt-4o".to_string()
        };

        info!("Using model: {}", model_name);

        // Modelã‚’ä½œæˆ
        let model = Model::new(
            model_name,
            None, // weak_model
            None, // editor_model
            None, // editor_edit_format
            false, // verbose
        )?;

        // LLMClientã‚’åˆæœŸåŒ–
        let llm_client = LLMClient::new(&model, api_key)?;

        // ConversationEngineã‚’åˆæœŸåŒ–
        let engine = ConversationEngine::with_project_root(project_root);

        // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        let messages = vec![Message::user(prompt.to_string())];

        // ã‚·ãƒ³ãƒ—ãƒ«ãªã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä½•ã‚‚ã—ãªã„ï¼‰
        struct NoOpCallback;

        #[async_trait]
        impl ToolCallback for NoOpCallback {
            async fn on_tool_start(&mut self, _tool_name: &str, _args: &str) {}
            async fn on_tool_complete(&mut self, _tool_name: &str, _result: &str) {}
            async fn on_response(&mut self, _text: &str) {}
            async fn on_response_chunk(&mut self, _chunk: &str) {}
        }

        let mut callback = NoOpCallback;

        info!("Sending prompt to LLM");

        // ConversationEngineã‚’ä½¿ã£ã¦å®Ÿè¡Œ
        let response = engine.execute(&llm_client, messages, project_root, &mut callback).await?;

        info!("LLM execution completed");

        Ok(response)
    }

    /// ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä½œæˆ
    pub async fn create_snapshot(
        execution_id: &str,
        node_id: &str,
        node_name: &str,
        project_root: &PathBuf,
        tracked_files: &[String],
    ) -> Result<WorkflowSnapshot> {
        info!("Creating snapshot for node {} in {}", node_id, execution_id);

        let mut file_snapshots = Vec::new();
        let timestamp = chrono::Utc::now().to_rfc3339();

        // è¿½è·¡å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä½œæˆ
        for file_path in tracked_files {
            let full_path = project_root.join(file_path);

            if full_path.exists() && full_path.is_file() {
                match tokio::fs::read_to_string(&full_path).await {
                    Ok(content) => {
                        file_snapshots.push(FileSnapshot {
                            file_path: file_path.clone(),
                            content,
                            timestamp: timestamp.clone(),
                        });
                    }
                    Err(e) => {
                        warn!("Failed to read file for snapshot {}: {}", file_path, e);
                    }
                }
            }
        }

        let snapshot = WorkflowSnapshot {
            snapshot_id: format!("{}-{}-{}", execution_id, node_id, uuid::Uuid::new_v4()),
            execution_id: execution_id.to_string(),
            node_id: node_id.to_string(),
            node_name: node_name.to_string(),
            files: file_snapshots,
            timestamp,
        };

        info!("Created snapshot {} with {} files", snapshot.snapshot_id, snapshot.files.len());
        Ok(snapshot)
    }

    /// ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰å¾©å…ƒ
    pub async fn restore_snapshot(
        snapshot: &WorkflowSnapshot,
        project_root: &PathBuf,
    ) -> Result<()> {
        info!("Restoring snapshot {}", snapshot.snapshot_id);

        for file_snapshot in &snapshot.files {
            let full_path = project_root.join(&file_snapshot.file_path);

            // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            if let Some(parent) = full_path.parent() {
                if !parent.exists() {
                    tokio::fs::create_dir_all(parent).await?;
                }
            }

            // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾©å…ƒ
            tokio::fs::write(&full_path, &file_snapshot.content).await?;
            info!("Restored file: {}", file_snapshot.file_path);
        }

        info!("Successfully restored {} files from snapshot {}",
              snapshot.files.len(), snapshot.snapshot_id);
        Ok(())
    }

    /// ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå¯¾è±¡ï¼‰
    pub async fn get_tracked_files(project_root: &PathBuf) -> Result<Vec<String>> {
        let mut tracked_files = Vec::new();

        // .git, node_modules, target ãªã©ã‚’é™¤å¤–ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
        let ignore_patterns = vec![
            ".git",
            "node_modules",
            "target",
            ".berrycode",
            "dist",
            "build",
            ".cache",
        ];

        fn visit_dirs(
            dir: &std::path::Path,
            root: &std::path::Path,
            files: &mut Vec<String>,
            ignore_patterns: &[&str],
        ) -> std::io::Result<()> {
            if dir.is_dir() {
                // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’ãƒã‚§ãƒƒã‚¯
                if let Some(dir_name) = dir.file_name().and_then(|n| n.to_str()) {
                    if ignore_patterns.contains(&dir_name) {
                        return Ok(());
                    }
                }

                for entry in std::fs::read_dir(dir)? {
                    let entry = entry?;
                    let path = entry.path();

                    if path.is_dir() {
                        visit_dirs(&path, root, files, ignore_patterns)?;
                    } else {
                        // ç›¸å¯¾ãƒ‘ã‚¹ã‚’ä¿å­˜
                        if let Ok(relative) = path.strip_prefix(root) {
                            if let Some(path_str) = relative.to_str() {
                                files.push(path_str.to_string());
                            }
                        }
                    }
                }
            }
            Ok(())
        }

        visit_dirs(project_root, project_root, &mut tracked_files, &ignore_patterns)?;

        info!("Found {} tracked files in project", tracked_files.len());
        Ok(tracked_files)
    }
}

/// TDDãƒ«ãƒ¼ãƒ—ã®ãƒ—ãƒªã‚»ãƒƒãƒˆ
pub fn create_tdd_loop_preset() -> Pipeline {
    let mut pipeline = Pipeline::new(
        "tdd-loop".to_string(),
        "TDD Loop (Test â†’ Fix â†’ Re-Test)".to_string(),
        "test".to_string(),
    );

    // ãƒ†ã‚¹ãƒˆãƒãƒ¼ãƒ‰
    pipeline.add_node(FlowNode {
        id: "test".to_string(),
        name: "ğŸ§ª Test".to_string(),
        action: NodeAction::Test,
        next_on_success: None, // ãƒ†ã‚¹ãƒˆæˆåŠŸã—ãŸã‚‰çµ‚äº†
        next_on_failure: Some("fix".to_string()), // å¤±æ•—ã—ãŸã‚‰ä¿®æ­£ã¸
        conditional_transitions: None,
        parallel_nodes: None,
    });

    // ä¿®æ­£ãƒãƒ¼ãƒ‰
    pipeline.add_node(FlowNode {
        id: "fix".to_string(),
        name: "ğŸ› Fix".to_string(),
        action: NodeAction::Fix,
        next_on_success: Some("test".to_string()), // ä¿®æ­£ã—ãŸã‚‰å†ãƒ†ã‚¹ãƒˆ
        next_on_failure: None,
        conditional_transitions: None,
        parallel_nodes: None,
    });

    pipeline.max_loops = 5;
    pipeline
}

/// ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯é–‹ç™ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
pub fn create_full_dev_pipeline() -> Pipeline {
    let mut pipeline = Pipeline::new(
        "full-dev".to_string(),
        "Full Development (Design â†’ Implement â†’ Test â†’ Fix â†’ Refactor)".to_string(),
        "design".to_string(),
    );

    // è¨­è¨ˆ
    pipeline.add_node(FlowNode {
        id: "design".to_string(),
        name: "ğŸ“ Design".to_string(),
        action: NodeAction::Design,
        next_on_success: Some("implement".to_string()),
        next_on_failure: None,
        conditional_transitions: None,
        parallel_nodes: None,
    });

    // å®Ÿè£…
    pipeline.add_node(FlowNode {
        id: "implement".to_string(),
        name: "ğŸ’» Implement".to_string(),
        action: NodeAction::Implement,
        next_on_success: Some("test".to_string()),
        next_on_failure: None,
        conditional_transitions: None,
        parallel_nodes: None,
    });

    // ãƒ†ã‚¹ãƒˆ
    pipeline.add_node(FlowNode {
        id: "test".to_string(),
        name: "ğŸ§ª Test".to_string(),
        action: NodeAction::Test,
        next_on_success: Some("refactor".to_string()),
        next_on_failure: Some("fix".to_string()),
        conditional_transitions: None,
        parallel_nodes: None,
    });

    // ä¿®æ­£
    pipeline.add_node(FlowNode {
        id: "fix".to_string(),
        name: "ğŸ› Fix".to_string(),
        action: NodeAction::Fix,
        next_on_success: Some("test".to_string()), // ä¿®æ­£ã—ãŸã‚‰å†ãƒ†ã‚¹ãƒˆ
        next_on_failure: None,
        conditional_transitions: None,
        parallel_nodes: None,
    });

    // ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
    pipeline.add_node(FlowNode {
        id: "refactor".to_string(),
        name: "ğŸ§¹ Refactor".to_string(),
        action: NodeAction::Refactor,
        next_on_success: None, // å®Œäº†
        next_on_failure: None,
        conditional_transitions: None,
        parallel_nodes: None,
    });

    pipeline.max_loops = 3;
    pipeline
}

impl Pipeline {
    /// HTTP APIã‚³ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
    async fn execute_http_request_static(
        url: &str,
        method: &str,
        headers: Option<&std::collections::HashMap<String, String>>,
        body: Option<&String>,
    ) -> Result<NodeResult> {
        info!("Executing HTTP request: {} {}", method, url);

        let client = reqwest::Client::new();
        let mut request = match method.to_uppercase().as_str() {
            "GET" => client.get(url),
            "POST" => client.post(url),
            "PUT" => client.put(url),
            "DELETE" => client.delete(url),
            "PATCH" => client.patch(url),
            _ => return Ok(NodeResult::Failure(format!("Unsupported HTTP method: {}", method))),
        };

        // ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
        if let Some(hdrs) = headers {
            for (key, value) in hdrs {
                request = request.header(key, value);
            }
        }

        // ãƒœãƒ‡ã‚£ã‚’è¿½åŠ 
        if let Some(b) = body {
            request = request.body(b.clone());
        }

        // ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        match request.send().await {
            Ok(response) => {
                let status = response.status();
                let body = response.text().await.unwrap_or_default();

                let output = format!(
                    "âœ… HTTP {} {}\nStatus: {}\nResponse:\n{}",
                    method.to_uppercase(),
                    url,
                    status,
                    body
                );

                if status.is_success() {
                    Ok(NodeResult::Success(output, ExecutionMetrics::default()))
                } else {
                    Ok(NodeResult::Failure(format!(
                        "âŒ HTTP request failed with status {}\nResponse: {}",
                        status, body
                    )))
                }
            }
            Err(e) => Ok(NodeResult::Failure(format!("âŒ HTTP request error: {}", e))),
        }
    }

    /// ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚’å®Ÿè¡Œï¼ˆç°¡æ˜“ç‰ˆ - JSONãƒ‘ãƒ¼ã‚¹/ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
    async fn execute_data_transform_static(
        input_context: &str,
        script: &str,
    ) -> Result<NodeResult> {
        info!("Executing data transform");

        // ç°¡æ˜“çš„ãªãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆè¨€èªãªã—ã§JSONæ“ä½œã®ã¿ï¼‰
        if script.starts_with("json.parse") {
            match serde_json::from_str::<serde_json::Value>(input_context) {
                Ok(json) => {
                    let formatted = serde_json::to_string_pretty(&json)?;
                    Ok(NodeResult::Success(
                        format!("âœ… JSON parsed:\n{}", formatted),
                        ExecutionMetrics::default(),
                    ))
                }
                Err(e) => Ok(NodeResult::Failure(format!("âŒ JSON parse error: {}", e))),
            }
        } else if script.starts_with("json.stringify") {
            // å…¥åŠ›ã‚’ãã®ã¾ã¾JSONã¨ã—ã¦æ•´å½¢
            Ok(NodeResult::Success(
                format!("âœ… JSON stringified:\n{}", input_context),
                ExecutionMetrics::default(),
            ))
        } else {
            // ãã®ä»–ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯å®Ÿè¡Œçµæœã‚’ãã®ã¾ã¾è¿”ã™
            Ok(NodeResult::Success(
                format!("âš ï¸ ãƒ‡ãƒ¼ã‚¿å¤‰æ›: {}\nå…¥åŠ›:\n{}", script, input_context),
                ExecutionMetrics::default(),
            ))
        }
    }

    /// ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã‚’å®Ÿè¡Œ
    async fn execute_file_operation_static(
        project_root: &PathBuf,
        operation: &str,
        file_path: &str,
        content: Option<&String>,
    ) -> Result<NodeResult> {
        info!("Executing file operation: {} on {}", operation, file_path);

        let full_path = project_root.join(file_path);

        match operation {
            "read" => {
                match tokio::fs::read_to_string(&full_path).await {
                    Ok(file_content) => Ok(NodeResult::Success(
                        format!("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {}\n\n{}", file_path, file_content),
                        ExecutionMetrics::default(),
                    )),
                    Err(e) => Ok(NodeResult::Failure(
                        format!("âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {}\n{}", file_path, e)
                    )),
                }
            }
            "write" => {
                if let Some(c) = content {
                    // è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                    if let Some(parent) = full_path.parent() {
                        tokio::fs::create_dir_all(parent).await?;
                    }

                    match tokio::fs::write(&full_path, c).await {
                        Ok(_) => Ok(NodeResult::Success(
                            format!("âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿æˆåŠŸ: {}\n\næ›¸ãè¾¼ã‚“ã å†…å®¹:\n{}", file_path, c),
                            ExecutionMetrics::default(),
                        )),
                        Err(e) => Ok(NodeResult::Failure(
                            format!("âŒ ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {}\n{}", file_path, e)
                        )),
                    }
                } else {
                    Ok(NodeResult::Failure(
                        "âŒ æ›¸ãè¾¼ã¿æ“ä½œã«ã¯contentãŒå¿…è¦ã§ã™".to_string()
                    ))
                }
            }
            _ => Ok(NodeResult::Failure(
                format!("âŒ ä¸æ˜ãªãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ: {}", operation)
            )),
        }
    }

    /// ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
    async fn execute_script_static(
        project_root: &PathBuf,
        language: &str,
        script: &str,
    ) -> Result<NodeResult> {
        info!("Executing {} script", language);

        let (command, args) = match language {
            "bash" | "sh" => ("sh", vec!["-c", script]),
            "python" | "python3" => ("python3", vec!["-c", script]),
            "node" | "javascript" | "js" => ("node", vec!["-e", script]),
            "ruby" => ("ruby", vec!["-e", script]),
            _ => return Ok(NodeResult::Failure(
                format!("âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„è¨€èª: {}", language)
            )),
        };

        let output = tokio::process::Command::new(command)
            .args(&args)
            .current_dir(project_root)
            .output()
            .await?;

        let stdout = String::from_utf8_lossy(&output.stdout);
        let stderr = String::from_utf8_lossy(&output.stderr);
        let combined = format!("{}\n{}", stdout, stderr);

        if output.status.success() {
            Ok(NodeResult::Success(
                format!("âœ… {} ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡ŒæˆåŠŸ:\n{}", language, combined),
                ExecutionMetrics::default(),
            ))
        } else {
            Ok(NodeResult::Failure(
                format!("âŒ {} ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œå¤±æ•—:\n{}", language, combined)
            ))
        }
    }
}
