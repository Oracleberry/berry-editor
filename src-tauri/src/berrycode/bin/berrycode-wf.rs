//! BerryCode Workflow Server
//!
//! A dedicated server for visual workflow building and execution.
//! Runs on port 7777, completely separate from the main editor.

use axum::{
    extract::{State, ws::{Message, WebSocket, WebSocketUpgrade}},
    http::StatusCode,
    response::{Html, IntoResponse, Json},
    routing::{get, post},
    Router,
};
use berrycode::{
    pipeline::{create_full_dev_pipeline, create_tdd_loop_preset},
    project_manager::ProjectManager,
};
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use tera::Tera;
use tokio::sync::Mutex;
use tower_http::services::ServeDir;
use tracing::{info, warn};
use chrono;

use berrycode::pipeline::WorkflowProgressMessage;

/// Application state
#[derive(Clone)]
struct AppState {
    tera: Arc<Tera>,
    project_manager: Arc<Mutex<ProjectManager>>,
    /// å®Ÿè¡Œä¸­ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    running_workflows: Arc<Mutex<HashMap<String, tokio::task::JoinHandle<()>>>>,
    /// é€²æ—ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼
    progress_broadcasters: Arc<Mutex<HashMap<String, tokio::sync::broadcast::Sender<WorkflowProgressMessage>>>>,
    /// LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
    llm_client: Arc<berrycode::llm::LLMClient>,
}

/// Workflow execution request
#[derive(Debug, Deserialize)]
struct ExecuteWorkflowRequest {
    /// ä¿å­˜æ¸ˆã¿ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®IDã€ã¾ãŸã¯ãƒ—ãƒªã‚»ãƒƒãƒˆID (tdd-loop, full-dev)
    workflow_id: Option<String>,
    /// ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ï¼ˆworkflow_idãŒãªã„å ´åˆï¼‰
    nodes: Option<Vec<WorkflowNodeDef>>,
    start_node_id: Option<String>,
    /// ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹
    project_path: String,
    /// åˆæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€æœ€åˆã®ãƒãƒ¼ãƒ‰ã«æ¸¡ã•ã‚Œã‚‹ï¼‰
    initial_context: Option<String>,
}

/// Workflow execution response
#[derive(Debug, Serialize)]
struct ExecuteWorkflowResponse {
    success: bool,
    execution_id: String,
    message: String,
}

/// Workflow validation request
#[derive(Debug, Deserialize)]
struct ValidateWorkflowRequest {
    nodes: Vec<WorkflowNodeDef>,
    start_node_id: Option<String>,
}

/// Workflow node definition
#[derive(Debug, Clone, Serialize, Deserialize)]
struct WorkflowNodeDef {
    id: String,
    name: String,
    /// ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—: design, implement, test, fix, refactor, doc, custom, http, script
    action_type: String,
    /// æˆåŠŸæ™‚ã®é·ç§»å…ˆãƒãƒ¼ãƒ‰ID
    next_on_success: Option<String>,
    /// å¤±æ•—æ™‚ã®é·ç§»å…ˆãƒãƒ¼ãƒ‰ID
    next_on_failure: Option<String>,

    // ãƒãƒ¼ãƒ‰å›ºæœ‰ã®è¨­å®š
    /// BerryCode Agentãƒ­ãƒ¼ãƒ«ï¼ˆdesign/implement/test/fix/refactor/docç”¨ï¼‰
    /// æŒ‡å®šã™ã‚‹ã¨ãã®Agentã®å°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä½¿ç”¨ã•ã‚Œã‚‹
    #[serde(default)]
    agent_role: Option<String>, // "Architect", "Programmer", "QAEngineer", "BugFixer", "Refactorer", "DocWriter"

    /// ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆagent_roleãŒãªã„å ´åˆã€ã¾ãŸã¯customã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”¨ï¼‰
    #[serde(default)]
    prompt: Option<String>,

    /// HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è¨­å®šï¼ˆhttpã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”¨ï¼‰
    #[serde(default)]
    http_config: Option<HttpConfig>,
    /// ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã®è¨­å®šï¼ˆscriptã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”¨ï¼‰
    #[serde(default)]
    script_config: Option<ScriptConfig>,
    /// è¿½åŠ ã®è¨­å®šï¼ˆJSONå½¢å¼ï¼‰
    #[serde(default)]
    config: Option<serde_json::Value>,
}

/// HTTP request configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
struct HttpConfig {
    url: String,
    method: String, // GET, POST, PUT, DELETE
    headers: Option<std::collections::HashMap<String, String>>,
    body: Option<String>,
}

/// Script execution configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
struct ScriptConfig {
    command: String,
    args: Option<Vec<String>>,
    working_dir: Option<String>,
}

/// Workflow validation response
#[derive(Debug, Serialize)]
struct ValidateWorkflowResponse {
    valid: bool,
    errors: Vec<String>,
    warnings: Vec<String>,
}

/// Saved workflow definition
#[derive(Debug, Clone, Serialize, Deserialize)]
struct SavedWorkflow {
    id: String,
    name: String,
    description: Option<String>,
    /// ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ï¼ˆå¿…é ˆã€Gitãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆï¼‰
    project_path: String,
    nodes: Vec<WorkflowNodeDef>,
    start_node_id: Option<String>,
    created_at: String,
    updated_at: String,
    #[serde(default)]
    deleted: bool,
}

/// Save workflow request
#[derive(Debug, Deserialize)]
struct SaveWorkflowRequest {
    id: Option<String>,
    name: String,
    description: Option<String>,
    /// ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ï¼ˆå¿…é ˆï¼‰
    project_path: String,
    nodes: Vec<WorkflowNodeDef>,
    start_node_id: Option<String>,
}

/// Save workflow response
#[derive(Debug, Serialize)]
struct SaveWorkflowResponse {
    success: bool,
    workflow_id: String,
    message: String,
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt::init();

    info!("Starting BerryCode Workflow Server");
    info!("Port: 7777");

    // Initialize Tera templates
    let tera = match Tera::new("templates/**/*") {
        Ok(t) => {
            #[cfg(debug_assertions)]
            info!("ğŸ”¥ Debug mode: Templates will be reloaded on each request");
            t
        }
        Err(e) => {
            warn!("Failed to load templates: {}", e);
            Tera::default()
        }
    };

    // Initialize project manager
    let project_manager = Arc::new(Mutex::new(ProjectManager::new()?));

    // Initialize LLM client
    use berrycode::llm::LLMClient;
    use berrycode::models::Model;

    let api_key = std::env::var("ANTHROPIC_API_KEY")
        .or_else(|_| std::env::var("OPENAI_API_KEY"))
        .unwrap_or_else(|_| {
            warn!("No API key found in environment. Agent execution will fail.");
            String::new()
        });

    // ãƒ¢ãƒ‡ãƒ«åã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: deepseek-reasonerï¼‰
    let model_name = std::env::var("BERRYCODE_MODEL")
        .unwrap_or_else(|_| "deepseek-reasoner".to_string());

    info!("Using model: {}", model_name);

    let model = Model::new(
        model_name,
        None,  // weak_model
        None,  // editor_model
        Some("diff".to_string()),  // editor_edit_format
        false,  // verbose
    )?;

    let mut llm_client = LLMClient::new(&model, api_key)?;

    // API baseã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®š
    if let Ok(api_base) = std::env::var("OPENAI_API_BASE") {
        info!("Using custom API base: {}", api_base);
        llm_client.set_api_base(api_base);
    }

    let llm_client = Arc::new(llm_client);

    let state = AppState {
        tera: Arc::new(tera),
        project_manager,
        running_workflows: Arc::new(Mutex::new(HashMap::new())),
        progress_broadcasters: Arc::new(Mutex::new(HashMap::new())),
        llm_client,
    };

    // ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    let workflows_dir = std::path::PathBuf::from("data/workflows");
    if !workflows_dir.exists() {
        std::fs::create_dir_all(&workflows_dir)?;
        info!("Created workflows directory: {:?}", workflows_dir);
    }

    // Build router
    let app = Router::new()
        .route("/", get(dashboard_handler))
        .route("/editor", get(editor_handler))
        .route("/workflows", get(workflows_page_handler))
        .route("/api/projects", get(list_projects_handler))
        .route("/api/projects", axum::routing::delete(delete_project_handler))
        .route("/api/projects/add", post(add_project_handler))
        .route("/api/projects/new", post(create_project_handler))
        .route("/api/projects/clone", post(clone_repository_handler))
        .route("/api/projects/files", post(list_project_files_handler))
        .route("/api/projects/read-files", post(read_project_files_handler))
        .route("/api/workflow/execute", post(execute_workflow_handler))
        .route("/api/workflow/validate", post(validate_workflow_handler))
        .route("/api/workflows", get(list_workflows_handler))
        .route("/api/workflows", post(save_workflow_handler))
        .route("/api/workflows/:id", get(get_workflow_handler))
        .route("/api/workflows/:id", axum::routing::delete(delete_workflow_handler))
        .route("/api/chat/agent", post(chat_with_agent_handler))
        .route("/api/save-document", post(save_document_handler))
        .route("/api/workflow/generate", post(generate_workflow_handler))
        .route("/api/ws/:execution_id", get(ws_handler))
        .nest_service("/static", ServeDir::new("static"))
        .with_state(state);

    // Start server
    let addr = "127.0.0.1:7777";
    let listener = tokio::net::TcpListener::bind(addr).await?;

    info!("ğŸš€ BerryCode Workflow Server starting on http://{}", addr);
    info!("   Open your browser and navigate to the URL above");

    axum::serve(listener, app).await?;

    Ok(())
}

/// Dashboard handler - main landing page
async fn dashboard_handler(State(state): State<AppState>) -> impl IntoResponse {
    let mut context = tera::Context::new();
    context.insert("version", env!("CARGO_PKG_VERSION"));

    // Reload templates in debug mode for hot reload
    #[cfg(debug_assertions)]
    let tera = Tera::new("templates/**/*").unwrap_or_default();
    #[cfg(not(debug_assertions))]
    let tera = &state.tera;

    match tera.render("dashboard.html", &context) {
        Ok(html) => Html(html).into_response(),
        Err(e) => {
            warn!("Failed to render dashboard template: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("Template error: {}", e),
            )
                .into_response()
        }
    }
}

/// Editor handler - workflow visual editor
async fn editor_handler(State(state): State<AppState>) -> impl IntoResponse {
    let mut context = tera::Context::new();
    context.insert("version", env!("CARGO_PKG_VERSION"));

    // Reload templates in debug mode for hot reload
    #[cfg(debug_assertions)]
    let tera = Tera::new("templates/**/*").unwrap_or_default();
    #[cfg(not(debug_assertions))]
    let tera = &state.tera;

    // Use v2 builder with n8n-style canvas
    match tera.render("workflow_builder_v2.html", &context) {
        Ok(html) => Html(html).into_response(),
        Err(e) => {
            warn!("Failed to render editor template: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("Template error: {}", e),
            )
                .into_response()
        }
    }
}

/// Workflows list page handler
async fn workflows_page_handler(State(state): State<AppState>) -> impl IntoResponse {
    let mut context = tera::Context::new();
    context.insert("version", env!("CARGO_PKG_VERSION"));

    // Reload templates in debug mode for hot reload
    #[cfg(debug_assertions)]
    let tera = Tera::new("templates/**/*").unwrap_or_default();
    #[cfg(not(debug_assertions))]
    let tera = &state.tera;

    match tera.render("workflows.html", &context) {
        Ok(html) => Html(html).into_response(),
        Err(e) => {
            warn!("Failed to render workflows template: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("Template error: {}", e),
            )
                .into_response()
        }
    }
}

/// List projects handler
async fn list_projects_handler(
    State(state): State<AppState>,
) -> impl IntoResponse {
    let pm = state.project_manager.lock().await;
    let projects = pm.list_projects();

    Json(serde_json::json!({
        "projects": projects
    }))
}

/// Execute workflow handler
async fn execute_workflow_handler(
    State(state): State<AppState>,
    Json(request): Json<ExecuteWorkflowRequest>,
) -> impl IntoResponse {
    // Generate execution ID
    let execution_id = format!("exec-{}", uuid::Uuid::new_v4());

    // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’PathBufã«å¤‰æ›
    let project_root = std::path::PathBuf::from(&request.project_path);

    // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å­˜åœ¨ç¢ºèª
    if !project_root.exists() {
        return Json(ExecuteWorkflowResponse {
            success: false,
            execution_id: execution_id.clone(),
            message: format!("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", request.project_path),
        });
    }

    // ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã‚’å–å¾—
    let (workflow_name, nodes, start_node_id) = if let Some(wf_id) = &request.workflow_id {
        // ãƒ—ãƒªã‚»ãƒƒãƒˆã¾ãŸã¯ä¿å­˜æ¸ˆã¿ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰
        match wf_id.as_str() {
            "tdd-loop" | "full-dev" => {
                // ãƒ—ãƒªã‚»ãƒƒãƒˆã®å ´åˆã¯å¾“æ¥ã®Pipelineå®Ÿè¡Œ
                info!("Executing preset workflow '{}' on project: {}", wf_id, request.project_path);

                let pipeline = match wf_id.as_str() {
                    "tdd-loop" => create_tdd_loop_preset(),
                    "full-dev" => create_full_dev_pipeline(),
                    _ => unreachable!(),
                };

                let pipeline_name = pipeline.name.clone();
                let initial_context = request.initial_context.clone().unwrap_or_default();
                let exec_id = execution_id.clone();

                // é€²æ—ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã‚’ä½œæˆ
                let (progress_tx, _) = tokio::sync::broadcast::channel::<WorkflowProgressMessage>(100);
                state.progress_broadcasters
                    .lock()
                    .await
                    .insert(exec_id.clone(), progress_tx.clone());

                let (tx, mut rx) = tokio::sync::mpsc::unbounded_channel();
                let progress_tx_clone = progress_tx.clone();

                tokio::spawn(async move {
                    while let Some(msg) = rx.recv().await {
                        let _ = progress_tx_clone.send(msg);
                    }
                });

                // ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
                let handle = tokio::spawn(async move {
                    info!("Starting preset pipeline execution: {} ({})", pipeline_name, exec_id);

                    match pipeline.run(
                        &project_root,
                        initial_context,
                        Some(tx),
                        Some(exec_id.clone()),
                        None, None, None, None,
                    ).await {
                        Ok(context) => {
                            info!("Pipeline completed: {} nodes, {} loops",
                                context.execution_history.len(), context.loop_count);
                        }
                        Err(e) => {
                            warn!("Pipeline failed: {} - {}", pipeline_name, e);
                        }
                    }
                });

                state.running_workflows.lock().await.insert(execution_id.clone(), handle);

                return Json(ExecuteWorkflowResponse {
                    success: true,
                    execution_id: execution_id.clone(),
                    message: format!("Preset workflow execution started: {}", execution_id),
                });
            }
            _ => {
                // ä¿å­˜æ¸ˆã¿ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰
                let workflows_dir = std::path::PathBuf::from("data/workflows");
                let workflow_path = workflows_dir.join(format!("{}.json", wf_id));

                if !workflow_path.exists() {
                    return Json(ExecuteWorkflowResponse {
                        success: false,
                        execution_id: execution_id.clone(),
                        message: format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", wf_id),
                    });
                }

                match std::fs::read_to_string(&workflow_path) {
                    Ok(content) => {
                        match serde_json::from_str::<SavedWorkflow>(&content) {
                            Ok(workflow) => {
                                info!("Executing saved workflow '{}' ({}) on project: {}",
                                    workflow.name, wf_id, request.project_path);
                                (workflow.name, workflow.nodes, workflow.start_node_id)
                            }
                            Err(e) => {
                                return Json(ExecuteWorkflowResponse {
                                    success: false,
                                    execution_id: execution_id.clone(),
                                    message: format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®è§£æã«å¤±æ•—: {}", e),
                                });
                            }
                        }
                    }
                    Err(e) => {
                        return Json(ExecuteWorkflowResponse {
                            success: false,
                            execution_id: execution_id.clone(),
                            message: format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {}", e),
                        });
                    }
                }
            }
        }
    } else if let Some(custom_nodes) = request.nodes {
        // ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
        info!("Executing custom workflow on project: {}", request.project_path);
        ("Custom Workflow".to_string(), custom_nodes, request.start_node_id)
    } else {
        return Json(ExecuteWorkflowResponse {
            success: false,
            execution_id: execution_id.clone(),
            message: "workflow_idã¾ãŸã¯nodesã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„".to_string(),
        });
    };

    // ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
    info!("Executing custom workflow '{}' with {} nodes", workflow_name, nodes.len());

    // é–‹å§‹ãƒãƒ¼ãƒ‰ã®ç¢ºèª
    let start_id = match start_node_id {
        Some(id) => id,
        None => {
            return Json(ExecuteWorkflowResponse {
                success: false,
                execution_id: execution_id.clone(),
                message: "é–‹å§‹ãƒãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“".to_string(),
            });
        }
    };

    let exec_id = execution_id.clone();
    let initial_ctx = request.initial_context.clone().unwrap_or_default();

    // é€²æ—ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã‚’ä½œæˆ
    let (progress_tx, _) = tokio::sync::broadcast::channel::<WorkflowProgressMessage>(100);
    state.progress_broadcasters
        .lock()
        .await
        .insert(exec_id.clone(), progress_tx.clone());

    let (tx, mut rx) = tokio::sync::mpsc::unbounded_channel();
    let progress_tx_clone = progress_tx.clone();

    tokio::spawn(async move {
        while let Some(msg) = rx.recv().await {
            let _ = progress_tx_clone.send(msg);
        }
    });

    // ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
    let workflow_name_clone = workflow_name.clone();
    let llm_client_clone = state.llm_client.clone();
    let handle = tokio::spawn(async move {
        info!("Starting custom workflow execution: {} ({})", workflow_name_clone, exec_id);

        match execute_custom_workflow(
            &project_root,
            &nodes,
            &start_id,
            &initial_ctx,
            tx,
            llm_client_clone,
        ).await {
            Ok(result) => {
                info!("Custom workflow completed: {} ({})", workflow_name_clone, exec_id);
                info!("Result: {}", result);
            }
            Err(e) => {
                warn!("Custom workflow failed: {} ({}): {}", workflow_name_clone, exec_id, e);
            }
        }
    });

    state.running_workflows.lock().await.insert(execution_id.clone(), handle);

    Json(ExecuteWorkflowResponse {
        success: true,
        execution_id: execution_id.clone(),
        message: format!("Custom workflow execution started: {}", execution_id),
    })
}

/// ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
async fn execute_custom_workflow(
    project_root: &std::path::PathBuf,
    nodes: &[WorkflowNodeDef],
    start_node_id: &str,
    initial_context: &str,
    progress_tx: tokio::sync::mpsc::UnboundedSender<WorkflowProgressMessage>,
    llm_client: Arc<berrycode::llm::LLMClient>,
) -> anyhow::Result<String> {
    use std::collections::HashMap;

    // ãƒãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’ä½œæˆ
    let node_map: HashMap<&str, &WorkflowNodeDef> = nodes
        .iter()
        .map(|node| (node.id.as_str(), node))
        .collect();

    // ç¾åœ¨ã®ãƒãƒ¼ãƒ‰IDã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    let mut current_node_id = start_node_id;
    let mut context = initial_context.to_string();
    let mut visited_count = 0;
    const MAX_ITERATIONS: usize = 100; // ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢

    loop {
        if visited_count >= MAX_ITERATIONS {
            return Err(anyhow::anyhow!("æœ€å¤§åå¾©å›æ•°ã«é”ã—ã¾ã—ãŸï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—ã®å¯èƒ½æ€§ï¼‰"));
        }
        visited_count += 1;

        // ç¾åœ¨ã®ãƒãƒ¼ãƒ‰ã‚’å–å¾—
        let node = match node_map.get(current_node_id) {
            Some(n) => n,
            None => {
                return Err(anyhow::anyhow!("ãƒãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", current_node_id));
            }
        };

        info!("Executing node: {} ({})", node.name, node.action_type);

        // é€²æ—é€ä¿¡
        let _ = progress_tx.send(WorkflowProgressMessage {
            node_id: node.id.clone(),
            node_name: node.name.clone(),
            status: "running".to_string(),
            message: format!("å®Ÿè¡Œä¸­: {}", node.name),
            loop_count: visited_count,
        });

        // ãƒãƒ¼ãƒ‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
        let (success, output) = execute_node_action(node, project_root, &context, llm_client.clone()).await?;

        // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
        context = output.clone();

        // æ¬¡ã®ãƒãƒ¼ãƒ‰ã‚’æ±ºå®š
        current_node_id = if success {
            match &node.next_on_success {
                Some(next_id) => next_id.as_str(),
                None => {
                    // çµ‚ç«¯ãƒãƒ¼ãƒ‰
                    info!("Workflow completed successfully at node: {}", node.name);
                    return Ok(output);
                }
            }
        } else {
            match &node.next_on_failure {
                Some(next_id) => next_id.as_str(),
                None => {
                    // å¤±æ•—çµ‚ç«¯
                    return Err(anyhow::anyhow!("Workflow failed at node: {}", node.name));
                }
            }
        };
    }
}

/// docs/é…ä¸‹ã®è¨­è¨ˆæ›¸ã‚’èª­ã¿è¾¼ã‚€
fn load_design_documents(project_root: &std::path::PathBuf) -> String {
    let docs_dir = project_root.join("docs");

    if !docs_dir.exists() {
        info!("docs/ directory not found in project");
        return String::new();
    }

    let mut design_docs = String::new();

    match std::fs::read_dir(&docs_dir) {
        Ok(entries) => {
            for entry in entries.flatten() {
                let path = entry.path();

                // .mdãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿èª­ã¿è¾¼ã‚€ï¼ˆREADME.mdã¯é™¤å¤–ï¼‰
                if path.extension().and_then(|s| s.to_str()) == Some("md") {
                    if let Some(filename) = path.file_name().and_then(|s| s.to_str()) {
                        if filename == "README.md" {
                            continue; // README.mdã¯ã‚¹ã‚­ãƒƒãƒ—
                        }

                        match std::fs::read_to_string(&path) {
                            Ok(content) => {
                                info!("Loaded design document: {:?}", path);
                                design_docs.push_str(&format!("\n\n## è¨­è¨ˆæ›¸: {}\n\n", filename));
                                design_docs.push_str(&content);
                            }
                            Err(e) => {
                                warn!("Failed to read design document {:?}: {}", path, e);
                            }
                        }
                    }
                }
            }
        }
        Err(e) => {
            warn!("Failed to read docs directory: {}", e);
        }
    }

    if !design_docs.is_empty() {
        info!("Loaded {} bytes of design documents", design_docs.len());
    }

    design_docs
}

/// å€‹åˆ¥ã®ãƒãƒ¼ãƒ‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
async fn execute_node_action(
    node: &WorkflowNodeDef,
    project_root: &std::path::PathBuf,
    context: &str,
    llm_client: Arc<berrycode::llm::LLMClient>,
) -> anyhow::Result<(bool, String)> {
    match node.action_type.as_str() {
        "design" | "implement" | "test" | "fix" | "refactor" | "doc" => {
            // BerryCode Agentã‚’ä½¿ç”¨
            use berrycode::agents::{AgentRole, AgentContext, AgentConfig, create_agent};
            use std::collections::HashMap;

            // AgentRoleã‚’æ±ºå®š
            let agent_role = if let Some(role_str) = &node.agent_role {
                match role_str.as_str() {
                    "Architect" => AgentRole::Architect,
                    "Programmer" => AgentRole::Programmer,
                    "QAEngineer" => AgentRole::QAEngineer,
                    "BugFixer" => AgentRole::BugFixer,
                    "Refactorer" => AgentRole::Refactorer,
                    "DocWriter" => AgentRole::DocWriter,
                    _ => {
                        match node.action_type.as_str() {
                            "design" => AgentRole::Architect,
                            "implement" => AgentRole::Programmer,
                            "test" => AgentRole::QAEngineer,
                            "fix" => AgentRole::BugFixer,
                            "refactor" => AgentRole::Refactorer,
                            "doc" => AgentRole::DocWriter,
                            _ => AgentRole::Programmer,
                        }
                    }
                }
            } else {
                match node.action_type.as_str() {
                    "design" => AgentRole::Architect,
                    "implement" => AgentRole::Programmer,
                    "test" => AgentRole::QAEngineer,
                    "fix" => AgentRole::BugFixer,
                    "refactor" => AgentRole::Refactorer,
                    "doc" => AgentRole::DocWriter,
                    _ => AgentRole::Programmer,
                }
            };

            let agent = create_agent(agent_role);

            info!(
                "Executing {} action for node: {} using Agent: {}",
                node.action_type, node.name, agent.name()
            );

            // ã‚¿ã‚¹ã‚¯ã‚’æ±ºå®š
            let task = node.prompt.as_deref().unwrap_or(context);

            // å®Ÿè£…ãƒãƒ¼ãƒ‰ã®å ´åˆã€docs/é…ä¸‹ã®è¨­è¨ˆæ›¸ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿
            let design_docs = if node.action_type == "implement" {
                load_design_documents(project_root)
            } else {
                String::new()
            };

            // AgentContextã‚’ä½œæˆ
            let mut inputs = HashMap::new();
            inputs.insert("task".to_string(), task.to_string());
            inputs.insert("context".to_string(), context.to_string());
            inputs.insert("requirement".to_string(), task.to_string());

            // è¨­è¨ˆæ›¸ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if !design_docs.is_empty() {
                inputs.insert("design_documents".to_string(), design_docs.clone());
                info!("Added design documents to agent context");

                // ã‚¿ã‚¹ã‚¯ã«è¨­è¨ˆæ›¸å‚ç…§ã®æŒ‡ç¤ºã‚’è¿½åŠ 
                let enhanced_task = format!(
                    "{}\n\n# è¨­è¨ˆæ›¸\n\nä»¥ä¸‹ã®è¨­è¨ˆæ›¸ã«åŸºã¥ã„ã¦å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚ã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„éƒ¨åˆ†ãŒã‚ã‚Œã°å„ªå…ˆçš„ã«å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚\n\n{}",
                    task,
                    design_docs
                );
                inputs.insert("task".to_string(), enhanced_task);
            }

            let agent_context = AgentContext {
                project_root: project_root.clone(),
                inputs,
                config: AgentConfig::default(),
                llm_client,
                repo_map: None, // TODO: RepoMapã‚’æ¸¡ã™å ´åˆã¯æ§‹ç¯‰ãŒå¿…è¦
            };

            // å®Ÿéš›ã®Agentå®Ÿè¡Œ
            match agent.execute(&agent_context).await {
                Ok(output) => {
                    info!("Agent {} completed successfully", agent.name());

                    // çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                    let result_text = if !output.files.is_empty() {
                        let mut result = format!("Agent: {}\n\nFiles modified:\n", agent.name());
                        for (path, _content) in output.files.iter() {
                            result.push_str(&format!("  - {}\n", path.display()));
                        }
                        result.push_str(&format!("\nMessage: {}\n", output.message));
                        result
                    } else {
                        format!("Agent: {}\n\nMessage: {}\n", agent.name(), output.message)
                    };

                    Ok((output.success, result_text))
                }
                Err(e) => {
                    warn!("Agent {} failed: {}", agent.name(), e);
                    Ok((false, format!("Agent execution failed: {}", e)))
                }
            }
        }
        "custom" => {
            // ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œ
            let prompt = node.prompt.as_deref().unwrap_or("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ");
            info!("Executing custom action with prompt: {}", prompt);
            Ok((true, format!("ã‚«ã‚¹ã‚¿ãƒ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³çµæœ: {}", prompt)))
        }
        "http" => {
            // HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
            if let Some(http_config) = &node.http_config {
                info!("Executing HTTP {} to {}", http_config.method, http_config.url);

                // å®Ÿéš›ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                let client = reqwest::Client::new();
                let response = match http_config.method.to_uppercase().as_str() {
                    "GET" => client.get(&http_config.url).send().await?,
                    "POST" => {
                        let mut req = client.post(&http_config.url);
                        if let Some(body) = &http_config.body {
                            req = req.body(body.clone());
                        }
                        req.send().await?
                    }
                    _ => return Err(anyhow::anyhow!("Unsupported HTTP method: {}", http_config.method)),
                };

                let status = response.status();
                let body = response.text().await?;

                Ok((status.is_success(), body))
            } else {
                Err(anyhow::anyhow!("HTTPè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“"))
            }
        }
        "script" => {
            // ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            if let Some(script_config) = &node.script_config {
                info!("Executing script: {}", script_config.command);

                let mut cmd = tokio::process::Command::new(&script_config.command);

                if let Some(args) = &script_config.args {
                    cmd.args(args);
                }

                if let Some(working_dir) = &script_config.working_dir {
                    cmd.current_dir(working_dir);
                } else {
                    cmd.current_dir(project_root);
                }

                let output = cmd.output().await?;

                let stdout = String::from_utf8_lossy(&output.stdout).to_string();
                let stderr = String::from_utf8_lossy(&output.stderr).to_string();

                let result = if stdout.is_empty() { stderr } else { stdout };

                Ok((output.status.success(), result))
            } else {
                Err(anyhow::anyhow!("ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“"))
            }
        }
        _ => {
            Err(anyhow::anyhow!("Unknown action type: {}", node.action_type))
        }
    }
}

/// Validate workflow handler
async fn validate_workflow_handler(
    Json(request): Json<ValidateWorkflowRequest>,
) -> impl IntoResponse {
    info!("Validating workflow with {} nodes", request.nodes.len());

    let mut errors = Vec::new();
    let mut warnings = Vec::new();

    // Check if workflow has nodes
    if request.nodes.is_empty() {
        errors.push("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ãƒãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“".to_string());
        return Json(ValidateWorkflowResponse {
            valid: false,
            errors,
            warnings,
        });
    }

    // Check if start node is specified
    if request.start_node_id.is_none() {
        errors.push("é–‹å§‹ãƒãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“".to_string());
    }

    // Build node map
    let mut node_map: HashMap<String, &WorkflowNodeDef> = HashMap::new();
    for node in &request.nodes {
        if node_map.contains_key(&node.id) {
            errors.push(format!("é‡è¤‡ã™ã‚‹ãƒãƒ¼ãƒ‰ID: {}", node.id));
        }
        node_map.insert(node.id.clone(), node);
    }

    // Check if start node exists
    if let Some(start_id) = &request.start_node_id {
        if !node_map.contains_key(start_id) {
            errors.push(format!("é–‹å§‹ãƒãƒ¼ãƒ‰ '{}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", start_id));
        }
    }

    // Check connections validity
    for node in &request.nodes {
        if let Some(next_id) = &node.next_on_success {
            if !node_map.contains_key(next_id) {
                errors.push(format!(
                    "ãƒãƒ¼ãƒ‰ '{}' ã®æˆåŠŸæ™‚é·ç§»å…ˆ '{}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    node.name, next_id
                ));
            }
        }
        if let Some(next_id) = &node.next_on_failure {
            if !node_map.contains_key(next_id) {
                errors.push(format!(
                    "ãƒãƒ¼ãƒ‰ '{}' ã®å¤±æ•—æ™‚é·ç§»å…ˆ '{}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    node.name, next_id
                ));
            }
        }
    }

    // Check for cycles (using DFS)
    if let Some(start_id) = &request.start_node_id {
        if node_map.contains_key(start_id) {
            let has_cycle = detect_cycle(start_id, &node_map);
            if has_cycle {
                errors.push("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ç„¡é™ãƒ«ãƒ¼ãƒ—ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ".to_string());
            }
        }
    }

    // Check for unreachable nodes
    if let Some(start_id) = &request.start_node_id {
        if node_map.contains_key(start_id) {
            let reachable = find_reachable_nodes(start_id, &node_map);
            for node in &request.nodes {
                if !reachable.contains(&node.id) {
                    warnings.push(format!(
                        "ãƒãƒ¼ãƒ‰ '{}' ã¯é–‹å§‹ãƒãƒ¼ãƒ‰ã‹ã‚‰åˆ°é”ã§ãã¾ã›ã‚“",
                        node.name
                    ));
                }
            }
        }
    }

    // Check for nodes without any outgoing connections (potential dead ends)
    for node in &request.nodes {
        if node.next_on_success.is_none() && node.next_on_failure.is_none() {
            warnings.push(format!(
                "ãƒãƒ¼ãƒ‰ '{}' ã«ã¯é·ç§»å…ˆãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆçµ‚ç«¯ãƒãƒ¼ãƒ‰ï¼‰",
                node.name
            ));
        }
    }

    let valid = errors.is_empty();
    info!(
        "Validation complete: valid={}, errors={}, warnings={}",
        valid,
        errors.len(),
        warnings.len()
    );

    Json(ValidateWorkflowResponse {
        valid,
        errors,
        warnings,
    })
}

/// Detect cycles in workflow graph using DFS
fn detect_cycle(
    start_id: &str,
    node_map: &HashMap<String, &WorkflowNodeDef>,
) -> bool {
    let mut visited = HashSet::new();
    let mut rec_stack = HashSet::new();
    dfs_cycle_detection(start_id, node_map, &mut visited, &mut rec_stack)
}

fn dfs_cycle_detection(
    node_id: &str,
    node_map: &HashMap<String, &WorkflowNodeDef>,
    visited: &mut HashSet<String>,
    rec_stack: &mut HashSet<String>,
) -> bool {
    if rec_stack.contains(node_id) {
        return true; // Cycle detected
    }
    if visited.contains(node_id) {
        return false; // Already visited, no cycle from here
    }

    visited.insert(node_id.to_string());
    rec_stack.insert(node_id.to_string());

    if let Some(node) = node_map.get(node_id) {
        // Check success path
        if let Some(next_id) = &node.next_on_success {
            if dfs_cycle_detection(next_id, node_map, visited, rec_stack) {
                return true;
            }
        }
        // Check failure path
        if let Some(next_id) = &node.next_on_failure {
            if dfs_cycle_detection(next_id, node_map, visited, rec_stack) {
                return true;
            }
        }
    }

    rec_stack.remove(node_id);
    false
}

/// Find all reachable nodes from start node
fn find_reachable_nodes(
    start_id: &str,
    node_map: &HashMap<String, &WorkflowNodeDef>,
) -> HashSet<String> {
    let mut reachable = HashSet::new();
    dfs_reachability(start_id, node_map, &mut reachable);
    reachable
}

fn dfs_reachability(
    node_id: &str,
    node_map: &HashMap<String, &WorkflowNodeDef>,
    reachable: &mut HashSet<String>,
) {
    if reachable.contains(node_id) {
        return; // Already visited
    }

    reachable.insert(node_id.to_string());

    if let Some(node) = node_map.get(node_id) {
        if let Some(next_id) = &node.next_on_success {
            dfs_reachability(next_id, node_map, reachable);
        }
        if let Some(next_id) = &node.next_on_failure {
            dfs_reachability(next_id, node_map, reachable);
        }
    }
}

/// Query parameters for listing workflows
#[derive(Debug, Deserialize)]
struct ListWorkflowsQuery {
    project_path: Option<String>,
}

/// List saved workflows handler
async fn list_workflows_handler(
    axum::extract::Query(query): axum::extract::Query<ListWorkflowsQuery>,
) -> impl IntoResponse {
    let workflows_dir = std::path::PathBuf::from("data/workflows");

    let mut workflows = Vec::new();

    if let Ok(entries) = std::fs::read_dir(&workflows_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            if path.extension().and_then(|s| s.to_str()) == Some("json") {
                if let Ok(content) = std::fs::read_to_string(&path) {
                    if let Ok(workflow) = serde_json::from_str::<SavedWorkflow>(&content) {
                        // Skip deleted workflows
                        if workflow.deleted {
                            continue;
                        }

                        // Filter by project_path if specified
                        if let Some(ref filter_path) = query.project_path {
                            if workflow.project_path == *filter_path {
                                workflows.push(workflow);
                            }
                        } else {
                            workflows.push(workflow);
                        }
                    }
                }
            }
        }
    }

    // Sort by updated_at descending
    workflows.sort_by(|a, b| b.updated_at.cmp(&a.updated_at));

    Json(serde_json::json!({
        "workflows": workflows
    }))
}

/// Save workflow handler
async fn save_workflow_handler(
    Json(request): Json<SaveWorkflowRequest>,
) -> impl IntoResponse {
    info!("Saving workflow: {}", request.name);

    let workflow_id = request.id.unwrap_or_else(|| format!("wf-{}", uuid::Uuid::new_v4()));
    let now = chrono::Utc::now().to_rfc3339();

    // Check if workflow exists to preserve created_at
    let workflows_dir = std::path::PathBuf::from("data/workflows");
    let workflow_path = workflows_dir.join(format!("{}.json", workflow_id));

    let created_at = if workflow_path.exists() {
        // Load existing workflow to preserve created_at
        match std::fs::read_to_string(&workflow_path) {
            Ok(content) => {
                match serde_json::from_str::<SavedWorkflow>(&content) {
                    Ok(existing) => existing.created_at,
                    Err(_) => now.clone(),
                }
            }
            Err(_) => now.clone(),
        }
    } else {
        now.clone()
    };

    let workflow = SavedWorkflow {
        id: workflow_id.clone(),
        name: request.name,
        description: request.description,
        project_path: request.project_path,
        nodes: request.nodes,
        start_node_id: request.start_node_id,
        created_at,
        updated_at: now,
        deleted: false,
    };

    match serde_json::to_string_pretty(&workflow) {
        Ok(json) => {
            match std::fs::write(&workflow_path, json) {
                Ok(_) => {
                    info!("Workflow saved successfully: {}", workflow_id);
                    Json(SaveWorkflowResponse {
                        success: true,
                        workflow_id: workflow_id.clone(),
                        message: format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {}", workflow_id),
                    })
                }
                Err(e) => {
                    warn!("Failed to save workflow: {}", e);
                    Json(SaveWorkflowResponse {
                        success: false,
                        workflow_id: workflow_id.clone(),
                        message: format!("ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e),
                    })
                }
            }
        }
        Err(e) => {
            warn!("Failed to serialize workflow: {}", e);
            Json(SaveWorkflowResponse {
                success: false,
                workflow_id: workflow_id.clone(),
                message: format!("ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e),
            })
        }
    }
}

/// Get workflow by ID handler
async fn get_workflow_handler(
    axum::extract::Path(id): axum::extract::Path<String>,
) -> impl IntoResponse {
    let workflows_dir = std::path::PathBuf::from("data/workflows");
    let workflow_path = workflows_dir.join(format!("{}.json", id));

    if !workflow_path.exists() {
        return (
            StatusCode::NOT_FOUND,
            Json(serde_json::json!({
                "error": "Workflow not found"
            }))
        ).into_response();
    }

    match std::fs::read_to_string(&workflow_path) {
        Ok(content) => {
            match serde_json::from_str::<SavedWorkflow>(&content) {
                Ok(workflow) => Json(workflow).into_response(),
                Err(e) => (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    Json(serde_json::json!({
                        "error": format!("Failed to parse workflow: {}", e)
                    }))
                ).into_response(),
            }
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "error": format!("Failed to read workflow: {}", e)
            }))
        ).into_response(),
    }
}

/// Delete workflow handler (logical delete)
async fn delete_workflow_handler(
    axum::extract::Path(id): axum::extract::Path<String>,
) -> impl IntoResponse {
    info!("Deleting workflow (logical): {}", id);

    let workflows_dir = std::path::PathBuf::from("data/workflows");
    let workflow_path = workflows_dir.join(format!("{}.json", id));

    if !workflow_path.exists() {
        return (
            StatusCode::NOT_FOUND,
            Json(serde_json::json!({
                "error": "Workflow not found"
            }))
        ).into_response();
    }

    // Read existing workflow
    match std::fs::read_to_string(&workflow_path) {
        Ok(content) => {
            match serde_json::from_str::<SavedWorkflow>(&content) {
                Ok(mut workflow) => {
                    // Set deleted flag
                    workflow.deleted = true;
                    workflow.updated_at = chrono::Utc::now().to_rfc3339();

                    // Save updated workflow
                    match serde_json::to_string_pretty(&workflow) {
                        Ok(json) => {
                            match std::fs::write(&workflow_path, json) {
                                Ok(_) => {
                                    info!("Workflow logically deleted: {}", id);
                                    Json(serde_json::json!({
                                        "success": true,
                                        "message": "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
                                    })).into_response()
                                }
                                Err(e) => {
                                    warn!("Failed to save deleted workflow: {}", e);
                                    (
                                        StatusCode::INTERNAL_SERVER_ERROR,
                                        Json(serde_json::json!({
                                            "error": format!("å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)
                                        }))
                                    ).into_response()
                                }
                            }
                        }
                        Err(e) => {
                            warn!("Failed to serialize workflow: {}", e);
                            (
                                StatusCode::INTERNAL_SERVER_ERROR,
                                Json(serde_json::json!({
                                    "error": format!("å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)
                                }))
                            ).into_response()
                        }
                    }
                }
                Err(e) => {
                    warn!("Failed to parse workflow: {}", e);
                    (
                        StatusCode::INTERNAL_SERVER_ERROR,
                        Json(serde_json::json!({
                            "error": format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)
                        }))
                    ).into_response()
                }
            }
        }
        Err(e) => {
            warn!("Failed to read workflow file: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({
                    "error": format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)
                }))
            ).into_response()
        }
    }
}

/// WebSocket handler for real-time progress updates
async fn ws_handler(
    ws: WebSocketUpgrade,
    axum::extract::Path(execution_id): axum::extract::Path<String>,
    State(state): State<AppState>,
) -> impl IntoResponse {
    ws.on_upgrade(move |socket| handle_socket(socket, execution_id, state))
}

async fn handle_socket(mut socket: WebSocket, execution_id: String, state: AppState) {
    info!("WebSocket connected for execution: {}", execution_id);

    // é€²æ—ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ã‚¿ãƒ¼ã‚’å–å¾—
    let progress_rx = {
        let broadcasters = state.progress_broadcasters.lock().await;
        match broadcasters.get(&execution_id) {
            Some(tx) => tx.subscribe(),
            None => {
                warn!("No progress broadcaster found for execution: {}", execution_id);
                let _ = socket.send(Message::Text(
                    serde_json::json!({
                        "error": "Execution not found"
                    }).to_string()
                )).await;
                return;
            }
        }
    };

    // é€²æ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’WebSocketã§è»¢é€
    let mut progress_rx = progress_rx;
    while let Ok(msg) = progress_rx.recv().await {
        let json = match serde_json::to_string(&msg) {
            Ok(j) => j,
            Err(e) => {
                warn!("Failed to serialize progress message: {}", e);
                continue;
            }
        };

        if socket.send(Message::Text(json)).await.is_err() {
            info!("WebSocket client disconnected");
            break;
        }
    }

    info!("WebSocket handler completed for execution: {}", execution_id);
}

/// Generate workflow request
#[derive(Debug, Deserialize)]
struct GenerateWorkflowRequest {
    project_path: String,
}

/// Generate workflow response
#[derive(Debug, Serialize)]
struct GenerateWorkflowResponse {
    success: bool,
    workflow: GeneratedWorkflow,
    description: String,
    message: Option<String>,
}

/// Generated workflow structure
#[derive(Debug, Serialize)]
struct GeneratedWorkflow {
    nodes: Vec<GeneratedNode>,
    connections: Vec<GeneratedConnection>,
}

/// Generated node
#[derive(Debug, Serialize)]
struct GeneratedNode {
    id: String,
    type_: String,
    #[serde(rename = "type")]
    type_field: String,
    name: String,
    x: i32,
    y: i32,
    config: serde_json::Value,
}

/// Generated connection
#[derive(Debug, Serialize)]
struct GeneratedConnection {
    #[serde(rename = "fromNodeId")]
    from_node_id: String,
    #[serde(rename = "toNodeId")]
    to_node_id: String,
    #[serde(rename = "fromPort")]
    from_port: String,
    #[serde(rename = "toPort")]
    to_port: String,
}

/// Generate workflow from project analysis
async fn generate_workflow_handler(
    State(state): State<AppState>,
    Json(request): Json<GenerateWorkflowRequest>,
) -> impl IntoResponse {
    info!("Generating workflow for project: {}", request.project_path);

    let project_path = std::path::PathBuf::from(&request.project_path);

    // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å­˜åœ¨ç¢ºèª
    if !project_path.exists() {
        return Json(serde_json::json!({
            "success": false,
            "message": format!("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", request.project_path)
        })).into_response();
    }

    // .gitãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    let git_dir = project_path.join(".git");
    if !git_dir.exists() {
        return Json(serde_json::json!({
            "success": false,
            "message": format!("ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯Gitãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {}\n.gitãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", request.project_path)
        })).into_response();
    }

    // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè§£æ
    let analysis = analyze_project(&project_path).await;

    // AIã«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ææ¡ˆã‚’ä¾é ¼
    use berrycode::llm::Message;

    let system_prompt = r#"ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æƒ…å ±ã‚’åˆ†æã—ã¦ã€æœ€é©ãªé–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ä»¥ä¸‹ã®ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™:
- design: è¨­è¨ˆãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¤œè¨
- implement: ã‚³ãƒ¼ãƒ‰å®Ÿè£…
- test: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- fix: ãƒã‚°ä¿®æ­£
- refactor: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
- doc: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ

JSONå½¢å¼ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹é€ ã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ææ¡ˆã—ã¦ãã ã•ã„:

{
  "description": "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®èª¬æ˜",
  "nodes": [
    {
      "id": "node-1",
      "type": "design",
      "name": "ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ",
      "prompt": "ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å…·ä½“çš„ãªæŒ‡ç¤º"
    },
    {
      "id": "node-2",
      "type": "implement",
      "name": "å®Ÿè£…",
      "prompt": null
    }
  ],
  "connections": [
    {
      "from": "node-1",
      "to": "node-2",
      "on": "success"
    }
  ]
}

JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜æ–‡ãªã©ã¯ä¸è¦ã§ã™ï¼‰ã€‚"#;

    let user_prompt = format!(
        r#"ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’åˆ†æã—ã¦ã€æœ€é©ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ææ¡ˆã—ã¦ãã ã•ã„:

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹: {}
è¨€èª: {}
ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {}
ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«: {}
READMEæ¦‚è¦: {}

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«é©ã—ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’JSONå½¢å¼ã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚"#,
        request.project_path,
        analysis.language,
        analysis.file_count,
        analysis.main_files.join(", "),
        analysis.readme_summary
    );

    let messages = vec![
        Message {
            role: "system".to_string(),
            content: Some(system_prompt.to_string()),
            tool_calls: None,
            tool_call_id: None,
        },
        Message {
            role: "user".to_string(),
            content: Some(user_prompt),
            tool_calls: None,
            tool_call_id: None,
        },
    ];

    match state.llm_client.chat(messages).await {
        Ok((response, _, _)) => {
            info!("Workflow proposal received: {} chars", response.len());

            // JSONã‚’ãƒ‘ãƒ¼ã‚¹
            let json_str = extract_json(&response);

            match serde_json::from_str::<serde_json::Value>(&json_str) {
                Ok(workflow_json) => {
                    // ãƒãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
                    let empty_vec = vec![];
                    let nodes_json = workflow_json["nodes"].as_array().unwrap_or(&empty_vec);
                    let mut nodes = Vec::new();

                    for (i, node_json) in nodes_json.iter().enumerate() {
                        let node_type = node_json["type"].as_str().unwrap_or("implement");
                        let node_id = node_json["id"]
                            .as_str()
                            .unwrap_or(&format!("node-{}", i + 1))
                            .to_string();

                        nodes.push(GeneratedNode {
                            id: node_id.clone(),
                            type_: node_type.to_string(),
                            type_field: node_type.to_string(),
                            name: node_json["name"]
                                .as_str()
                                .unwrap_or("Untitled")
                                .to_string(),
                            x: 100 + (i as i32 % 3) * 250,
                            y: 100 + (i as i32 / 3) * 150,
                            config: serde_json::json!({
                                "prompt": node_json.get("prompt")
                            }),
                        });
                    }

                    // ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
                    let empty_connections = vec![];
                    let connections_json = workflow_json["connections"]
                        .as_array()
                        .unwrap_or(&empty_connections);
                    let mut connections = Vec::new();

                    for conn_json in connections_json {
                        let from_id = conn_json["from"].as_str().unwrap_or("").to_string();
                        let to_id = conn_json["to"].as_str().unwrap_or("").to_string();
                        let on = conn_json["on"].as_str().unwrap_or("success");

                        connections.push(GeneratedConnection {
                            from_node_id: from_id,
                            to_node_id: to_id,
                            from_port: on.to_string(),
                            to_port: "input".to_string(),
                        });
                    }

                    let description = workflow_json["description"]
                        .as_str()
                        .unwrap_or("AIç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼")
                        .to_string();

                    Json(GenerateWorkflowResponse {
                        success: true,
                        workflow: GeneratedWorkflow { nodes, connections },
                        description,
                        message: None,
                    })
                    .into_response()
                }
                Err(e) => {
                    warn!("Failed to parse workflow JSON: {}", e);
                    warn!("Response: {}", response);

                    Json(serde_json::json!({
                        "success": false,
                        "message": format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)
                    }))
                    .into_response()
                }
            }
        }
        Err(e) => {
            warn!("LLM error: {}", e);
            Json(serde_json::json!({
                "success": false,
                "message": format!("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)
            }))
            .into_response()
        }
    }
}

/// Project analysis result
struct ProjectAnalysis {
    language: String,
    file_count: usize,
    main_files: Vec<String>,
    readme_summary: String,
}

/// Analyze project to understand its structure
async fn analyze_project(project_path: &std::path::PathBuf) -> ProjectAnalysis {
    use std::fs;

    let mut language = "Unknown".to_string();
    let mut file_count = 0;
    let mut main_files = Vec::new();
    let mut readme_summary = "No README found".to_string();

    // è¨€èªæ¤œå‡º
    if project_path.join("Cargo.toml").exists() {
        language = "Rust".to_string();
        main_files.push("Cargo.toml".to_string());
        if project_path.join("src/main.rs").exists() {
            main_files.push("src/main.rs".to_string());
        }
        if project_path.join("src/lib.rs").exists() {
            main_files.push("src/lib.rs".to_string());
        }
    } else if project_path.join("package.json").exists() {
        language = "JavaScript/TypeScript".to_string();
        main_files.push("package.json".to_string());
    } else if project_path.join("requirements.txt").exists()
        || project_path.join("setup.py").exists()
    {
        language = "Python".to_string();
        if project_path.join("requirements.txt").exists() {
            main_files.push("requirements.txt".to_string());
        }
    } else if project_path.join("go.mod").exists() {
        language = "Go".to_string();
        main_files.push("go.mod".to_string());
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    if let Ok(entries) = fs::read_dir(project_path) {
        for entry in entries.flatten() {
            if let Ok(file_type) = entry.file_type() {
                if file_type.is_file() {
                    file_count += 1;
                }
            }
        }
    }

    // READMEèª­ã¿è¾¼ã¿
    let readme_paths = ["README.md", "README.txt", "README"];
    for readme_name in &readme_paths {
        let readme_path = project_path.join(readme_name);
        if readme_path.exists() {
            if let Ok(content) = fs::read_to_string(&readme_path) {
                // æœ€åˆã®500æ–‡å­—ã‚’æ¦‚è¦ã¨ã—ã¦ä½¿ç”¨
                readme_summary = content.chars().take(500).collect();
                readme_summary = readme_summary
                    .lines()
                    .take(10)
                    .collect::<Vec<_>>()
                    .join("\n");
                break;
            }
        }
    }

    ProjectAnalysis {
        language,
        file_count,
        main_files,
        readme_summary,
    }
}

/// Extract JSON from LLM response (remove markdown code blocks etc.)
fn extract_json(text: &str) -> String {
    // JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆ```json ... ``` ã¾ãŸã¯ { ... }ï¼‰
    if let Some(start) = text.find("```json") {
        if let Some(end) = text[start..].find("```") {
            let json_content = &text[start + 7..start + end];
            return json_content.trim().to_string();
        }
    }

    // { ã§å§‹ã¾ã‚‹éƒ¨åˆ†ã‚’æ¢ã™
    if let Some(start) = text.find('{') {
        if let Some(end) = text.rfind('}') {
            return text[start..=end].to_string();
        }
    }

    text.trim().to_string()
}

/// Chat message history
#[derive(Debug, Deserialize)]
struct ChatMessage {
    role: String,
    content: String,
}

/// Chat with agent request
#[derive(Debug, Deserialize)]
struct ChatWithAgentRequest {
    agent_role: String,
    message: String,
    #[serde(default)]
    history: Vec<ChatMessage>,
}

/// Chat with agent response
#[derive(Debug, Serialize)]
struct ChatWithAgentResponse {
    response: String,
}

/// Chat with agent handler - interactive design/implementation chat
async fn chat_with_agent_handler(
    State(state): State<AppState>,
    Json(request): Json<ChatWithAgentRequest>,
) -> impl IntoResponse {
    info!("Chat with agent: {} - {}", request.agent_role, request.message);

    // AgentRoleã‚’æ±ºå®š
    use berrycode::agents::{AgentRole, create_agent};
    use berrycode::llm::Message;

    let agent_role = match request.agent_role.as_str() {
        "Architect" => AgentRole::Architect,
        "Programmer" => AgentRole::Programmer,
        "QAEngineer" => AgentRole::QAEngineer,
        "BugFixer" => AgentRole::BugFixer,
        "Refactorer" => AgentRole::Refactorer,
        "DocWriter" => AgentRole::DocWriter,
        _ => AgentRole::Architect, // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    };

    let agent = create_agent(agent_role);

    // LLMã«æ¸¡ã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
    let mut messages = Vec::new();

    // ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    let system_content = format!(
        "ã‚ãªãŸã¯{}ã§ã™ã€‚\n\n{}",
        agent.name(),
        agent.system_prompt()
    );
    messages.push(Message {
        role: "system".to_string(),
        content: Some(system_content),
        tool_calls: None,
        tool_call_id: None,
    });

    // ä¼šè©±å±¥æ­´
    for msg in &request.history {
        messages.push(Message {
            role: msg.role.clone(),
            content: Some(msg.content.clone()),
            tool_calls: None,
            tool_call_id: None,
        });
    }

    // ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    messages.push(Message {
        role: "user".to_string(),
        content: Some(request.message.clone()),
        tool_calls: None,
        tool_call_id: None,
    });

    // LLMã§å›ç­”ã‚’ç”Ÿæˆ
    match state.llm_client.chat(messages).await {
        Ok((response, _input_tokens, _output_tokens)) => {
            info!("Agent response generated: {} chars", response.len());
            Json(ChatWithAgentResponse {
                response: response.trim().to_string(),
            }).into_response()
        }
        Err(e) => {
            warn!("LLM error: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({
                    "error": format!("LLMå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)
                }))
            ).into_response()
        }
    }
}

/// Save document request
#[derive(Debug, Deserialize)]
struct SaveDocumentRequest {
    filename: String,
    content: String,
    agent_role: Option<String>,
    #[serde(default)]
    append: bool,
}

/// Save document response
#[derive(Debug, Serialize)]
struct SaveDocumentResponse {
    success: bool,
    filepath: String,
    message: String,
}

/// Save document handler - saves chat results as markdown files
async fn save_document_handler(
    Json(request): Json<SaveDocumentRequest>,
) -> impl IntoResponse {
    info!("Saving document: {}", request.filename);

    // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    let docs_dir = std::path::PathBuf::from("docs");
    if !docs_dir.exists() {
        if let Err(e) = std::fs::create_dir_all(&docs_dir) {
            warn!("Failed to create docs directory: {}", e);
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({
                    "success": false,
                    "error": format!("ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—: {}", e)
                }))
            ).into_response();
        }
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä½œæˆ
    let filepath = docs_dir.join(&request.filename);

    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆ
    let mut full_content = String::new();

    if request.append && filepath.exists() {
        // è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è¿½è¨˜
        match std::fs::read_to_string(&filepath) {
            Ok(existing_content) => {
                full_content.push_str(&existing_content);
                full_content.push_str(&format!("\n\n---\n\n## è¿½è¨˜ ({})\n\n", chrono::Utc::now().format("%Y-%m-%d %H:%M")));
                full_content.push_str(&request.content);
                info!("Appending to existing document: {:?}", filepath);
            }
            Err(e) => {
                warn!("Failed to read existing file for append: {}", e);
                // èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯æ–°è¦ä½œæˆ
                full_content.push_str(&format!("---\n"));
                full_content.push_str(&format!("generated_at: {}\n", chrono::Utc::now().to_rfc3339()));
                if let Some(agent_role) = &request.agent_role {
                    full_content.push_str(&format!("agent_role: {}\n", agent_role));
                }
                full_content.push_str(&format!("---\n\n"));
                full_content.push_str(&request.content);
            }
        }
    } else {
        // æ–°è¦ä½œæˆã¾ãŸã¯ä¸Šæ›¸ããƒ¢ãƒ¼ãƒ‰
        full_content.push_str(&format!("---\n"));
        full_content.push_str(&format!("generated_at: {}\n", chrono::Utc::now().to_rfc3339()));
        if let Some(agent_role) = &request.agent_role {
            full_content.push_str(&format!("agent_role: {}\n", agent_role));
        }
        full_content.push_str(&format!("---\n\n"));
        full_content.push_str(&request.content);
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    match std::fs::write(&filepath, full_content) {
        Ok(_) => {
            info!("Document saved successfully: {:?}", filepath);

            // README.mdã‚’æ›´æ–°
            if let Err(e) = update_docs_readme(&docs_dir) {
                warn!("Failed to update README.md: {}", e);
            }

            Json(SaveDocumentResponse {
                success: true,
                filepath: filepath.to_string_lossy().to_string(),
                message: "è¨­è¨ˆæ›¸ã‚’ä¿å­˜ã—ã¾ã—ãŸ".to_string(),
            }).into_response()
        }
        Err(e) => {
            warn!("Failed to save document: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({
                    "success": false,
                    "error": format!("ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—: {}", e)
                }))
            ).into_response()
        }
    }
}

/// Update docs/README.md with list of all documents
fn update_docs_readme(docs_dir: &std::path::PathBuf) -> anyhow::Result<()> {
    use std::fs;

    let mut readme_content = String::new();

    // ãƒ˜ãƒƒãƒ€ãƒ¼
    readme_content.push_str("# BerryCode ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\n\n");
    readme_content.push_str("ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€BerryCode AIãƒãƒ£ãƒƒãƒˆã§ç”Ÿæˆã•ã‚ŒãŸè¨­è¨ˆæ›¸ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n");
    readme_content.push_str(&format!("æœ€çµ‚æ›´æ–°: {}\n\n", chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC")));

    // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã‚’åé›†
    let mut documents: Vec<(String, String, String)> = Vec::new(); // (filename, generated_at, agent_role)

    if let Ok(entries) = fs::read_dir(docs_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            if path.extension().and_then(|s| s.to_str()) == Some("md")
                && path.file_name().and_then(|s| s.to_str()) != Some("README.md")
            {
                if let Ok(content) = fs::read_to_string(&path) {
                    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                    let mut generated_at = "ä¸æ˜".to_string();
                    let mut agent_role = "ä¸æ˜".to_string();

                    if content.starts_with("---\n") {
                        if let Some(end_idx) = content[4..].find("---\n") {
                            let metadata = &content[4..4 + end_idx];
                            for line in metadata.lines() {
                                if let Some(value) = line.strip_prefix("generated_at: ") {
                                    if let Ok(dt) = chrono::DateTime::parse_from_rfc3339(value) {
                                        generated_at = dt.format("%Y-%m-%d %H:%M").to_string();
                                    }
                                } else if let Some(value) = line.strip_prefix("agent_role: ") {
                                    agent_role = value.to_string();
                                }
                            }
                        }
                    }

                    if let Some(filename) = path.file_name().and_then(|s| s.to_str()) {
                        documents.push((filename.to_string(), generated_at, agent_role));
                    }
                }
            }
        }
    }

    // ç”Ÿæˆæ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    documents.sort_by(|a, b| b.1.cmp(&a.1));

    // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ã‚’ä½œæˆ
    readme_content.push_str("## ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§\n\n");

    if documents.is_empty() {
        readme_content.push_str("_ã¾ã ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“_\n");
    } else {
        readme_content.push_str("| ãƒ•ã‚¡ã‚¤ãƒ« | ç”Ÿæˆæ—¥æ™‚ | AI Agent |\n");
        readme_content.push_str("|---------|---------|----------|\n");

        for (filename, generated_at, agent_role) in documents {
            readme_content.push_str(&format!(
                "| [{}](./{}) | {} | {} |\n",
                filename, filename, generated_at, agent_role
            ));
        }
    }

    readme_content.push_str("\n---\n\n");
    readme_content.push_str("_ã“ã®README.mdã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™_\n");

    // README.mdã‚’ä¿å­˜
    let readme_path = docs_dir.join("README.md");
    fs::write(&readme_path, readme_content)?;

    info!("Updated README.md: {:?}", readme_path);

    Ok(())
}

/// List project files request
#[derive(Debug, Deserialize)]
struct ListProjectFilesRequest {
    project_path: String,
}

/// Project file info
#[derive(Debug, Serialize)]
struct ProjectFileInfo {
    path: String,
    relative_path: String,
    is_dir: bool,
    extension: Option<String>,
}

/// List project files response
#[derive(Debug, Serialize)]
struct ListProjectFilesResponse {
    files: Vec<ProjectFileInfo>,
}

/// List project files handler - returns all source files in a project
async fn list_project_files_handler(
    Json(request): Json<ListProjectFilesRequest>,
) -> impl IntoResponse {
    info!("Listing files for project: {}", request.project_path);

    let project_root = std::path::PathBuf::from(&request.project_path);

    if !project_root.exists() {
        return (
            StatusCode::BAD_REQUEST,
            Json(serde_json::json!({
                "error": format!("Project not found: {}", request.project_path)
            }))
        ).into_response();
    }

    let mut files = Vec::new();

    // é™¤å¤–ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    let exclude_dirs = vec![
        "target", "node_modules", ".git", "dist", "build",
        ".next", ".vscode", ".idea", "data", "static"
    ];

    // å«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
    let include_extensions = vec![
        "rs", "toml", "md", "js", "ts", "jsx", "tsx", "py",
        "go", "java", "cpp", "c", "h", "html", "css", "json", "yaml", "yml"
    ];

    fn walk_dir(
        dir: &std::path::Path,
        project_root: &std::path::Path,
        files: &mut Vec<ProjectFileInfo>,
        exclude_dirs: &[&str],
        include_extensions: &[&str],
    ) -> std::io::Result<()> {
        if !dir.is_dir() {
            return Ok(());
        }

        for entry in std::fs::read_dir(dir)? {
            let entry = entry?;
            let path = entry.path();
            let file_name = path.file_name().and_then(|s| s.to_str()).unwrap_or("");

            // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆ
            if path.is_dir() {
                // é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—
                if exclude_dirs.contains(&file_name) {
                    continue;
                }
                // å†å¸°çš„ã«æ¢ç´¢
                walk_dir(&path, project_root, files, exclude_dirs, include_extensions)?;
            } else {
                // ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€æ‹¡å¼µå­ã‚’ãƒã‚§ãƒƒã‚¯
                if let Some(ext) = path.extension().and_then(|s| s.to_str()) {
                    if include_extensions.contains(&ext) {
                        let relative_path = path.strip_prefix(project_root)
                            .unwrap_or(&path)
                            .to_string_lossy()
                            .to_string();

                        files.push(ProjectFileInfo {
                            path: path.to_string_lossy().to_string(),
                            relative_path,
                            is_dir: false,
                            extension: Some(ext.to_string()),
                        });
                    }
                }
            }
        }

        Ok(())
    }

    match walk_dir(&project_root, &project_root, &mut files, &exclude_dirs, &include_extensions) {
        Ok(_) => {
            // ãƒ‘ã‚¹ã§ã‚½ãƒ¼ãƒˆ
            files.sort_by(|a, b| a.relative_path.cmp(&b.relative_path));

            info!("Found {} files in project", files.len());

            Json(ListProjectFilesResponse { files }).into_response()
        }
        Err(e) => {
            warn!("Failed to list project files: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({
                    "error": format!("Failed to list files: {}", e)
                }))
            ).into_response()
        }
    }
}

/// Read project files request
#[derive(Debug, Deserialize)]
struct ReadProjectFilesRequest {
    file_paths: Vec<String>,
}

/// File content
#[derive(Debug, Serialize)]
struct FileContent {
    path: String,
    content: String,
    error: Option<String>,
}

/// Read project files response
#[derive(Debug, Serialize)]
struct ReadProjectFilesResponse {
    files: Vec<FileContent>,
}

/// Read multiple project files handler
async fn read_project_files_handler(
    Json(request): Json<ReadProjectFilesRequest>,
) -> impl IntoResponse {
    info!("Reading {} files", request.file_paths.len());

    let mut files = Vec::new();

    for file_path in request.file_paths {
        let path = std::path::PathBuf::from(&file_path);

        match std::fs::read_to_string(&path) {
            Ok(content) => {
                files.push(FileContent {
                    path: file_path,
                    content,
                    error: None,
                });
            }
            Err(e) => {
                warn!("Failed to read file {}: {}", file_path, e);
                files.push(FileContent {
                    path: file_path.clone(),
                    content: String::new(),
                    error: Some(format!("Failed to read: {}", e)),
                });
            }
        }
    }

    Json(ReadProjectFilesResponse { files }).into_response()
}

// ========== Project Management Handlers ==========

/// Delete project from history
#[derive(Debug, Deserialize)]
struct DeleteProjectRequest {
    path: String,
}

#[derive(Debug, Serialize)]
struct DeleteProjectResponse {
    status: String,
}

async fn delete_project_handler(
    State(state): State<AppState>,
    axum::extract::Query(params): axum::extract::Query<DeleteProjectRequest>,
) -> impl IntoResponse {
    info!("Deleting project from history: {}", params.path);

    let mut pm = state.project_manager.lock().await;
    let path = std::path::PathBuf::from(&params.path);

    match pm.remove_project(&path) {
        Ok(_) => Json(DeleteProjectResponse {
            status: "deleted".to_string(),
        })
        .into_response(),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "error": format!("Failed to delete project: {}", e)
            })),
        )
            .into_response(),
    }
}

/// Add existing project
#[derive(Debug, Deserialize)]
struct AddProjectRequest {
    path: String,
}

#[derive(Debug, Serialize)]
struct AddProjectResponse {
    path: String,
    status: String,
}

async fn add_project_handler(
    State(state): State<AppState>,
    Json(payload): Json<AddProjectRequest>,
) -> impl IntoResponse {
    info!("Adding existing project: {}", payload.path);

    let mut pm = state.project_manager.lock().await;
    let path = std::path::PathBuf::from(&payload.path);

    // Check if path exists
    if !path.exists() {
        return (
            StatusCode::BAD_REQUEST,
            Json(serde_json::json!({"error": format!("ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", payload.path)})),
        )
            .into_response();
    }

    // Check if it's a directory
    if !path.is_dir() {
        return (
            StatusCode::BAD_REQUEST,
            Json(serde_json::json!({"error": format!("æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {}", payload.path)})),
        )
            .into_response();
    }

    // Add to project manager
    match pm.add_or_update_project(path.clone()) {
        Ok(_) => Json(AddProjectResponse {
            path: path.to_string_lossy().to_string(),
            status: "added".to_string(),
        })
        .into_response(),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({"error": format!("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ: {}", e)})),
        )
            .into_response(),
    }
}

/// Create new project
#[derive(Debug, Deserialize)]
struct CreateProjectRequest {
    name: String,
    path: Option<String>,
    init_git: Option<bool>,
}

#[derive(Debug, Serialize)]
struct CreateProjectResponse {
    path: String,
    status: String,
}

async fn create_project_handler(
    State(state): State<AppState>,
    Json(payload): Json<CreateProjectRequest>,
) -> impl IntoResponse {
    info!("Creating new project: {}", payload.name);

    let mut pm = state.project_manager.lock().await;

    let path = payload
        .path
        .map(std::path::PathBuf::from)
        .unwrap_or_else(|| std::env::current_dir().unwrap().join(&payload.name));

    // Create directory
    if let Err(e) = std::fs::create_dir_all(&path) {
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "error": format!("Failed to create directory: {}", e)
            })),
        )
            .into_response();
    }

    // Initialize git if requested
    if payload.init_git.unwrap_or(true) {
        let output = std::process::Command::new("git")
            .args(&["init"])
            .current_dir(&path)
            .output();

        if let Err(e) = output {
            warn!("Failed to initialize git: {}", e);
        }
    }

    // Add to project manager
    match pm.add_or_update_project(path.clone()) {
        Ok(_) => Json(CreateProjectResponse {
            path: path.to_string_lossy().to_string(),
            status: "created".to_string(),
        })
        .into_response(),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "error": format!("Failed to register project: {}", e)
            })),
        )
            .into_response(),
    }
}

/// Clone repository
#[derive(Debug, Deserialize)]
struct CloneRepositoryRequest {
    url: String,
    dest: Option<String>,
}

#[derive(Debug, Serialize)]
struct CloneRepositoryResponse {
    path: String,
    status: String,
}

async fn clone_repository_handler(
    State(state): State<AppState>,
    Json(payload): Json<CloneRepositoryRequest>,
) -> impl IntoResponse {
    info!("Cloning repository: {}", payload.url);

    let mut pm = state.project_manager.lock().await;

    // Extract repository name from URL
    let repo_name = payload
        .url
        .split('/')
        .last()
        .and_then(|s| s.strip_suffix(".git").or(Some(s)))
        .unwrap_or("cloned-repo");

    let dest = payload
        .dest
        .map(std::path::PathBuf::from)
        .unwrap_or_else(|| std::env::current_dir().unwrap().join(repo_name));

    // Clone repository using git
    let output = std::process::Command::new("git")
        .args(&["clone", &payload.url, dest.to_str().unwrap()])
        .output();

    match output {
        Ok(output) if output.status.success() => {
            // Add to project manager
            match pm.add_or_update_project(dest.clone()) {
                Ok(_) => Json(CloneRepositoryResponse {
                    path: dest.to_string_lossy().to_string(),
                    status: "cloned".to_string(),
                })
                .into_response(),
                Err(e) => (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    Json(serde_json::json!({
                        "error": format!("Failed to register project: {}", e)
                    })),
                )
                    .into_response(),
            }
        }
        Ok(output) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "error": format!(
                    "Git clone failed: {}",
                    String::from_utf8_lossy(&output.stderr)
                )
            })),
        )
            .into_response(),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "error": format!("Failed to execute git: {}", e)
            })),
        )
            .into_response(),
    }
}
